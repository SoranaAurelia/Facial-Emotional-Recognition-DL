{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example_submission.csv',\n",
       " 'fer2013.tar.gz',\n",
       " 'icml_face_data.csv',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path+'icml_face_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     Usage                                             pixels\n",
       "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_all_emotions(train_images, emotions, train_labels):\n",
    "    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n",
    "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "    for i in range(7):\n",
    "        idx = data[data['emotion']==i].index[i]\n",
    "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
    "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Usage\n",
       "Training       28709\n",
       "PublicTest      3589\n",
       "PrivateTest     3589\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[' Usage'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\n",
    "val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\n",
    "test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\n",
    "val_images = val_images.astype('float32')/255\n",
    "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 ... 4 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_ecnoding(labels):\n",
    "    labels_one_hot_encoded = np.zeros((len(labels), 7))\n",
    "    for i, label in enumerate(labels):\n",
    "        labels_one_hot_encoded[i, label] = 1\n",
    "    return labels_one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3589,)\n"
     ]
    }
   ],
   "source": [
    "print(val_image_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = one_hot_ecnoding(train_image_label)\n",
    "val_labels = one_hot_ecnoding(val_image_label)\n",
    "test_labels = one_hot_ecnoding(test_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3589, 1, 48, 48])\n",
      "torch.Size([3589, 7])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "tensor_train_x = torch.Tensor(train_images).permute(0, 3, 1, 2)\n",
    "tensor_train_y = torch.Tensor(train_labels)\n",
    "\n",
    "train_set = TensorDataset(tensor_train_x, tensor_train_y)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4,\n",
    "                                           shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "tensor_val_x = torch.Tensor(val_images).permute(0, 3, 1, 2)\n",
    "tensor_val_y = torch.Tensor(val_labels)\n",
    "\n",
    "print(tensor_val_x.shape)\n",
    "print(tensor_val_y.shape)\n",
    "\n",
    "val_set = TensorDataset(tensor_val_x, tensor_val_y)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=4,\n",
    "                                           shuffle=True, num_workers=4)\n",
    "\n",
    "tensor_test_x = torch.Tensor(test_images).permute(0, 3, 1, 2)\n",
    "tensor_test_y = torch.Tensor(test_labels)\n",
    "\n",
    "test_set = TensorDataset(tensor_test_x, tensor_test_y)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4,\n",
    "                                           shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1200 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_all_emotions(train_images, emotions, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception v_1"
   ]
  },
  {
   "attachments": {
    "inception_block_1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic Inception block:\n",
    "\n",
    "![inception_block_1.png](attachment:inception_block_1.png)\n",
    "\n",
    "\n",
    "\\[2] - Szegedy, Christian, et al. Going Deeper with Convolutions. arXiv:1409.4842, arXiv, 16 septembrie 2014. arXiv.org, https://doi.org/10.48550/arXiv.1409.4842.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Layer consisting of conv->batchnorm->relu\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels , out_channels , kernel_size , stride , padding , activation='relu', norm='batch'):\n",
    "        super(ConvolutionBlock,self).__init__()\n",
    "\n",
    "        # 2d convolution\n",
    "        self.conv2d = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding , bias=False )\n",
    "\n",
    "        # batchnorm\n",
    "        if norm == 'batch':\n",
    "            self.batchnorm2d = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if activation == 'relu':\n",
    "        # relu layer\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv2d(x)\n",
    "        if self.batchnorm2d is not None:\n",
    "            x = self.batchnorm2d(x)\n",
    "        \n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Users\\\\soca274177\\\\Downloads\\\\graphviz-9.0.0-win32\\\\Graphviz\\\\bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:19612): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n",
      "\n",
      "(dot.exe:29816): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Title: self_InceptionBlock Pages: 1 -->\n",
       "<svg width=\"908pt\" height=\"717pt\"\n",
       " viewBox=\"0.00 0.00 908.00 717.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 713)\">\n",
       "<title>self_InceptionBlock</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-713 904,-713 904,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-392.25 8,-636.75 210,-636.75 210,-392.25 8,-392.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.88\" y=\"-621.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ConvolutionBlock</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"218,-134 218,-667 440,-667 440,-134 218,-134\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.25\" y=\"-651.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"229,-392.25 229,-636.75 431,-636.75 431,-392.25 229,-392.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.88\" y=\"-621.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ConvolutionBlock</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"226,-142 226,-384.25 432,-384.25 432,-142 226,-142\"/>\n",
       "<text text-anchor=\"middle\" x=\"274.88\" y=\"-368.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ConvolutionBlock</text>\n",
       "</g>\n",
       "<g id=\"clust5\" class=\"cluster\">\n",
       "<title>cluster_6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"448,-134 448,-667 666,-667 666,-134 448,-134\"/>\n",
       "<text text-anchor=\"middle\" x=\"479.25\" y=\"-651.6\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust6\" class=\"cluster\">\n",
       "<title>cluster_7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"456,-392.25 456,-636.75 658,-636.75 658,-392.25 456,-392.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"504.88\" y=\"-621.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ConvolutionBlock</text>\n",
       "</g>\n",
       "<g id=\"clust7\" class=\"cluster\">\n",
       "<title>cluster_8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"456,-142 456,-384.25 658,-384.25 658,-142 456,-142\"/>\n",
       "<text text-anchor=\"middle\" x=\"504.88\" y=\"-368.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ConvolutionBlock</text>\n",
       "</g>\n",
       "<g id=\"clust8\" class=\"cluster\">\n",
       "<title>cluster_9</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"674,-294 674,-636.75 892,-636.75 892,-294 674,-294\"/>\n",
       "<text text-anchor=\"middle\" x=\"705.25\" y=\"-621.35\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust9\" class=\"cluster\">\n",
       "<title>cluster_10</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"682,-302 682,-554.5 884,-554.5 884,-302 682,-302\"/>\n",
       "<text text-anchor=\"middle\" x=\"730.88\" y=\"-539.1\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ConvolutionBlock</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"515.62,-709 376.38,-709 376.38,-675 515.62,-675 515.62,-709\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"376.38,-675 376.38,-709 438.12,-709 438.12,-675 376.38,-675\"/>\n",
       "<text text-anchor=\"start\" x=\"381.38\" y=\"-694.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"390.75\" y=\"-682.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"438.12,-675 438.12,-709 515.62,-709 515.62,-675 438.12,-675\"/>\n",
       "<text text-anchor=\"start\" x=\"443.12\" y=\"-688.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"197,-606.5 31,-606.5 31,-562.5 197,-562.5 197,-606.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"31,-562.5 31,-606.5 74,-606.5 74,-562.5 31,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"36.75\" y=\"-587\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"36\" y=\"-575\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"74,-584.5 74,-606.5 117,-606.5 117,-584.5 74,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"83.12\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117,-584.5 117,-606.5 197,-606.5 197,-584.5 117,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"121.75\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"74,-562.5 74,-584.5 117,-584.5 117,-562.5 74,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"78.62\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117,-562.5 117,-584.5 197,-584.5 197,-562.5 117,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"124.38\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.49,-687.39C322.27,-683.84 251.8,-677.42 225,-667 194.19,-655.02 164.29,-632.21 143.3,-613.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.76,-611.28 135.99,-607.18 141.08,-616.48 145.76,-611.28\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"418,-606.5 252,-606.5 252,-562.5 418,-562.5 418,-606.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"252,-562.5 252,-606.5 295,-606.5 295,-562.5 252,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"257.75\" y=\"-587\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"257\" y=\"-575\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"295,-584.5 295,-606.5 338,-606.5 338,-584.5 295,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"304.12\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"338,-584.5 338,-606.5 418,-606.5 418,-584.5 338,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"342.75\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"295,-562.5 295,-584.5 338,-584.5 338,-562.5 295,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"299.62\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"338,-562.5 338,-584.5 418,-584.5 418,-562.5 338,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"345.38\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429.62,-675.43C412.66,-659.31 385.78,-633.77 365,-614.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.55,-611.61 357.89,-607.26 362.73,-616.69 367.55,-611.61\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"635,-606.5 469,-606.5 469,-562.5 635,-562.5 635,-606.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"469,-562.5 469,-606.5 512,-606.5 512,-562.5 469,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"474.75\" y=\"-587\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"474\" y=\"-575\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"512,-584.5 512,-606.5 555,-606.5 555,-584.5 512,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"521.12\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"555,-584.5 555,-606.5 635,-606.5 635,-584.5 555,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"559.75\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"512,-562.5 512,-584.5 555,-584.5 555,-562.5 512,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"516.62\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"555,-562.5 555,-584.5 635,-584.5 635,-562.5 555,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"562.38\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>0&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M461.64,-675.43C477.77,-659.38 503.28,-633.99 523.09,-614.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"525.49,-616.82 530.11,-607.29 520.55,-611.86 525.49,-616.82\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"861,-606.5 683,-606.5 683,-562.5 861,-562.5 861,-606.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"683,-562.5 683,-606.5 738,-606.5 738,-562.5 683,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"687.62\" y=\"-587\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool2d</text>\n",
       "<text text-anchor=\"start\" x=\"694\" y=\"-575\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"738,-584.5 738,-606.5 781,-606.5 781,-584.5 738,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"747.12\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"781,-584.5 781,-606.5 861,-606.5 861,-584.5 781,-584.5\"/>\n",
       "<text text-anchor=\"start\" x=\"785.75\" y=\"-592\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"738,-562.5 738,-584.5 781,-584.5 781,-562.5 738,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"742.62\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"781,-562.5 781,-584.5 861,-584.5 861,-562.5 781,-562.5\"/>\n",
       "<text text-anchor=\"start\" x=\"785.75\" y=\"-570\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;16 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>0&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M515.55,-687.2C568.34,-683.59 636.1,-677.17 662,-667 692.59,-654.99 722.22,-632.18 743,-613.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"745.19,-616.49 750.23,-607.17 740.48,-611.31 745.19,-616.49\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"201.5,-524.25 16.5,-524.25 16.5,-480.25 201.5,-480.25 201.5,-524.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16.5,-480.25 16.5,-524.25 83.5,-524.25 83.5,-480.25 16.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-504.75\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"33.5\" y=\"-492.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-502.25 83.5,-524.25 126.5,-524.25 126.5,-502.25 83.5,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"92.62\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"126.5,-502.25 126.5,-524.25 201.5,-524.25 201.5,-502.25 126.5,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"131.38\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-480.25 83.5,-502.25 126.5,-502.25 126.5,-480.25 83.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"88.12\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"126.5,-480.25 126.5,-502.25 201.5,-502.25 201.5,-480.25 126.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"131.38\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.71,-562.83C112.19,-554.47 111.58,-544.63 111,-535.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.51,-535.4 110.39,-525.64 107.52,-535.83 114.51,-535.4\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"195.5,-444.25 34.5,-444.25 34.5,-400.25 195.5,-400.25 195.5,-444.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34.5,-400.25 34.5,-444.25 77.5,-444.25 77.5,-400.25 34.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"45.12\" y=\"-424.75\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"39.5\" y=\"-412.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-422.25 77.5,-444.25 120.5,-444.25 120.5,-422.25 77.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"86.62\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-422.25 120.5,-444.25 195.5,-444.25 195.5,-422.25 120.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"125.38\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-400.25 77.5,-422.25 120.5,-422.25 120.5,-400.25 77.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"82.12\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120.5,-400.25 120.5,-422.25 195.5,-422.25 195.5,-400.25 120.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"125.38\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.61,-480.35C111.19,-472.74 111.87,-463.95 112.51,-455.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.99,-455.96 113.27,-445.72 109.01,-455.42 115.99,-455.96\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"605,-114 287,-114 287,-70 605,-70 605,-114\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"287,-70 287,-114 330,-114 330,-70 287,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"302.12\" y=\"-94.5\" font-family=\"Linux libertine\" font-size=\"10.00\">cat</text>\n",
       "<text text-anchor=\"start\" x=\"292\" y=\"-82.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"330,-92 330,-114 373,-114 373,-92 330,-92\"/>\n",
       "<text text-anchor=\"start\" x=\"339.12\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"373,-92 373,-114 605,-114 605,-92 373,-92\"/>\n",
       "<text text-anchor=\"start\" x=\"377.62\" y=\"-99.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 28, 28), (1, 128, 28, 28), 2 x (1, 32, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"330,-70 330,-92 373,-92 373,-70 330,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"334.62\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"373,-70 373,-92 605,-92 605,-70 373,-70\"/>\n",
       "<text text-anchor=\"start\" x=\"453.75\" y=\"-77.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;20 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116.06,-400.33C119.98,-346.82 138.19,-204.25 222,-134 232.1,-125.54 252.11,-118.7 276.2,-113.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.62,-116.71 285.67,-111.19 275.16,-109.87 276.62,-116.71\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"422.5,-524.25 237.5,-524.25 237.5,-480.25 422.5,-480.25 422.5,-524.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"237.5,-480.25 237.5,-524.25 304.5,-524.25 304.5,-480.25 237.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"242.5\" y=\"-504.75\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"254.5\" y=\"-492.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"304.5,-502.25 304.5,-524.25 347.5,-524.25 347.5,-502.25 304.5,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"313.62\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"347.5,-502.25 347.5,-524.25 422.5,-524.25 422.5,-502.25 347.5,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"352.38\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"304.5,-480.25 304.5,-502.25 347.5,-502.25 347.5,-480.25 304.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"309.12\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"347.5,-480.25 347.5,-502.25 422.5,-502.25 422.5,-480.25 347.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"352.38\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.71,-562.83C333.19,-554.47 332.58,-544.63 332,-535.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"335.51,-535.4 331.39,-525.64 328.52,-535.83 335.51,-535.4\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"409.5,-444.25 248.5,-444.25 248.5,-400.25 409.5,-400.25 409.5,-444.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"248.5,-400.25 248.5,-444.25 291.5,-444.25 291.5,-400.25 248.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"259.12\" y=\"-424.75\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"253.5\" y=\"-412.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"291.5,-422.25 291.5,-444.25 334.5,-444.25 334.5,-422.25 291.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"300.62\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"334.5,-422.25 334.5,-444.25 409.5,-444.25 409.5,-422.25 334.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"339.38\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"291.5,-400.25 291.5,-422.25 334.5,-422.25 334.5,-400.25 291.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"296.12\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"334.5,-400.25 334.5,-422.25 409.5,-422.25 409.5,-400.25 334.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"339.38\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329.73,-480.35C329.63,-472.74 329.52,-463.95 329.41,-455.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.92,-455.68 329.29,-445.72 325.92,-455.77 332.92,-455.68\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"412,-354 246,-354 246,-310 412,-310 412,-354\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"246,-310 246,-354 289,-354 289,-310 246,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"251.75\" y=\"-334.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"251\" y=\"-322.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"289,-332 289,-354 332,-354 332,-332 289,-332\"/>\n",
       "<text text-anchor=\"start\" x=\"298.12\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"332,-332 332,-354 412,-354 412,-332 332,-332\"/>\n",
       "<text text-anchor=\"start\" x=\"339.38\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 96, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"289,-310 289,-332 332,-332 332,-310 289,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"293.62\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"332,-310 332,-332 412,-332 412,-310 332,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"336.75\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329,-400.34C329,-389.79 329,-376.76 329,-364.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.5,-365.28 329,-355.28 325.5,-365.28 332.5,-365.28\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"424,-274 234,-274 234,-230 424,-230 424,-274\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"234,-230 234,-274 301,-274 301,-230 234,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"239\" y=\"-254.5\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"251\" y=\"-242.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"301,-252 301,-274 344,-274 344,-252 301,-252\"/>\n",
       "<text text-anchor=\"start\" x=\"310.12\" y=\"-259.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"344,-252 344,-274 424,-274 424,-252 344,-252\"/>\n",
       "<text text-anchor=\"start\" x=\"348.75\" y=\"-259.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"301,-230 301,-252 344,-252 344,-230 301,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"305.62\" y=\"-237.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"344,-230 344,-252 424,-252 424,-230 344,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"348.75\" y=\"-237.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329,-310.1C329,-302.49 329,-293.7 329,-285.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332.5,-285.47 329,-275.47 325.5,-285.47 332.5,-285.47\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"418,-194 252,-194 252,-150 418,-150 418,-194\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"252,-150 252,-194 295,-194 295,-150 252,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"262.62\" y=\"-174.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"257\" y=\"-162.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"295,-172 295,-194 338,-194 338,-172 295,-172\"/>\n",
       "<text text-anchor=\"start\" x=\"304.12\" y=\"-179.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"338,-172 338,-194 418,-194 418,-172 338,-172\"/>\n",
       "<text text-anchor=\"start\" x=\"342.75\" y=\"-179.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"295,-150 295,-172 338,-172 338,-150 295,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"299.62\" y=\"-157.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"338,-150 338,-172 418,-172 418,-150 338,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"342.75\" y=\"-157.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330.61,-230.1C331.19,-222.49 331.87,-213.7 332.51,-205.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"335.99,-205.71 333.27,-195.47 329.01,-205.17 335.99,-205.71\"/>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;20 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M364.75,-150.1C377.69,-141 393.03,-130.23 406.87,-120.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.76,-123.44 414.93,-114.83 404.74,-117.72 408.76,-123.44\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"649.5,-524.25 464.5,-524.25 464.5,-480.25 649.5,-480.25 649.5,-524.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"464.5,-480.25 464.5,-524.25 531.5,-524.25 531.5,-480.25 464.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"469.5\" y=\"-504.75\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"481.5\" y=\"-492.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-502.25 531.5,-524.25 574.5,-524.25 574.5,-502.25 531.5,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"540.62\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"574.5,-502.25 574.5,-524.25 649.5,-524.25 649.5,-502.25 574.5,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"579.38\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-480.25 531.5,-502.25 574.5,-502.25 574.5,-480.25 531.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"536.12\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"574.5,-480.25 574.5,-502.25 649.5,-502.25 649.5,-480.25 574.5,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"579.38\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M553.29,-562.83C553.81,-554.47 554.42,-544.63 555,-535.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"558.48,-535.83 555.61,-525.64 551.49,-535.4 558.48,-535.83\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"637.5,-444.25 476.5,-444.25 476.5,-400.25 637.5,-400.25 637.5,-444.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"476.5,-400.25 476.5,-444.25 519.5,-444.25 519.5,-400.25 476.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"487.12\" y=\"-424.75\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"481.5\" y=\"-412.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"519.5,-422.25 519.5,-444.25 562.5,-444.25 562.5,-422.25 519.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"528.62\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"562.5,-422.25 562.5,-444.25 637.5,-444.25 637.5,-422.25 562.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"567.38\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"519.5,-400.25 519.5,-422.25 562.5,-422.25 562.5,-400.25 519.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"524.12\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"562.5,-400.25 562.5,-422.25 637.5,-422.25 637.5,-400.25 562.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"567.38\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557,-480.35C557,-472.74 557,-463.95 557,-455.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"560.5,-455.72 557,-445.72 553.5,-455.72 560.5,-455.72\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"637.5,-354 476.5,-354 476.5,-310 637.5,-310 637.5,-354\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"476.5,-310 476.5,-354 519.5,-354 519.5,-310 476.5,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"482.25\" y=\"-334.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"481.5\" y=\"-322.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"519.5,-332 519.5,-354 562.5,-354 562.5,-332 519.5,-332\"/>\n",
       "<text text-anchor=\"start\" x=\"528.62\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"562.5,-332 562.5,-354 637.5,-354 637.5,-332 562.5,-332\"/>\n",
       "<text text-anchor=\"start\" x=\"567.38\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 16, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"519.5,-310 519.5,-332 562.5,-332 562.5,-310 519.5,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"524.12\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"562.5,-310 562.5,-332 637.5,-332 637.5,-310 562.5,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"567.38\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557,-400.34C557,-389.79 557,-376.76 557,-364.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"560.5,-365.28 557,-355.28 553.5,-365.28 560.5,-365.28\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"649.5,-274 464.5,-274 464.5,-230 649.5,-230 649.5,-274\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"464.5,-230 464.5,-274 531.5,-274 531.5,-230 464.5,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"469.5\" y=\"-254.5\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"481.5\" y=\"-242.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-252 531.5,-274 574.5,-274 574.5,-252 531.5,-252\"/>\n",
       "<text text-anchor=\"start\" x=\"540.62\" y=\"-259.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"574.5,-252 574.5,-274 649.5,-274 649.5,-252 574.5,-252\"/>\n",
       "<text text-anchor=\"start\" x=\"579.38\" y=\"-259.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-230 531.5,-252 574.5,-252 574.5,-230 531.5,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"536.12\" y=\"-237.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"574.5,-230 574.5,-252 649.5,-252 649.5,-230 574.5,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"579.38\" y=\"-237.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557,-310.1C557,-302.49 557,-293.7 557,-285.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"560.5,-285.47 557,-275.47 553.5,-285.47 560.5,-285.47\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"631.5,-194 470.5,-194 470.5,-150 631.5,-150 631.5,-194\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"470.5,-150 470.5,-194 513.5,-194 513.5,-150 470.5,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"481.12\" y=\"-174.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"475.5\" y=\"-162.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"513.5,-172 513.5,-194 556.5,-194 556.5,-172 513.5,-172\"/>\n",
       "<text text-anchor=\"start\" x=\"522.62\" y=\"-179.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"556.5,-172 556.5,-194 631.5,-194 631.5,-172 556.5,-172\"/>\n",
       "<text text-anchor=\"start\" x=\"561.38\" y=\"-179.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"513.5,-150 513.5,-172 556.5,-172 556.5,-150 513.5,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"518.12\" y=\"-157.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"556.5,-150 556.5,-172 631.5,-172 631.5,-150 556.5,-150\"/>\n",
       "<text text-anchor=\"start\" x=\"561.38\" y=\"-157.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M555.39,-230.1C554.81,-222.49 554.13,-213.7 553.49,-205.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"556.99,-205.17 552.73,-195.47 550.01,-205.71 556.99,-205.17\"/>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;20 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>15&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.86,-150.1C510.74,-141.09 496.39,-130.43 483.39,-120.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"485.55,-118.02 475.43,-114.86 481.37,-123.64 485.55,-118.02\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"861,-524.25 695,-524.25 695,-480.25 861,-480.25 861,-524.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"695,-480.25 695,-524.25 738,-524.25 738,-480.25 695,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"700.75\" y=\"-504.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"700\" y=\"-492.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"738,-502.25 738,-524.25 781,-524.25 781,-502.25 738,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"747.12\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"781,-502.25 781,-524.25 861,-524.25 861,-502.25 781,-502.25\"/>\n",
       "<text text-anchor=\"start\" x=\"785.75\" y=\"-509.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 192, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"738,-480.25 738,-502.25 781,-502.25 781,-480.25 738,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"742.62\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"781,-480.25 781,-502.25 861,-502.25 861,-480.25 781,-480.25\"/>\n",
       "<text text-anchor=\"start\" x=\"788.38\" y=\"-487.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M773.55,-562.83C774.17,-554.47 774.91,-544.63 775.6,-535.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"779.07,-535.87 776.33,-525.63 772.09,-535.35 779.07,-535.87\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"875.5,-444.25 690.5,-444.25 690.5,-400.25 875.5,-400.25 875.5,-444.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"690.5,-400.25 690.5,-444.25 757.5,-444.25 757.5,-400.25 690.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"695.5\" y=\"-424.75\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"707.5\" y=\"-412.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"757.5,-422.25 757.5,-444.25 800.5,-444.25 800.5,-422.25 757.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"766.62\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"800.5,-422.25 800.5,-444.25 875.5,-444.25 875.5,-422.25 800.5,-422.25\"/>\n",
       "<text text-anchor=\"start\" x=\"805.38\" y=\"-429.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"757.5,-400.25 757.5,-422.25 800.5,-422.25 800.5,-400.25 757.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"762.12\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"800.5,-400.25 800.5,-422.25 875.5,-422.25 875.5,-400.25 800.5,-400.25\"/>\n",
       "<text text-anchor=\"start\" x=\"805.38\" y=\"-407.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M779.34,-480.35C779.83,-472.74 780.39,-463.95 780.93,-455.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"784.41,-455.92 781.56,-445.72 777.43,-455.48 784.41,-455.92\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"857.5,-354 696.5,-354 696.5,-310 857.5,-310 857.5,-354\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"696.5,-310 696.5,-354 739.5,-354 739.5,-310 696.5,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"707.12\" y=\"-334.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"701.5\" y=\"-322.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"739.5,-332 739.5,-354 782.5,-354 782.5,-332 739.5,-332\"/>\n",
       "<text text-anchor=\"start\" x=\"748.62\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"782.5,-332 782.5,-354 857.5,-354 857.5,-332 782.5,-332\"/>\n",
       "<text text-anchor=\"start\" x=\"787.38\" y=\"-339.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"739.5,-310 739.5,-332 782.5,-332 782.5,-310 739.5,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"744.12\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"782.5,-310 782.5,-332 857.5,-332 857.5,-310 782.5,-310\"/>\n",
       "<text text-anchor=\"start\" x=\"787.38\" y=\"-317.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;19 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>18&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M781.58,-400.34C780.86,-389.79 779.98,-376.76 779.17,-364.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"782.68,-365.01 778.51,-355.27 775.7,-365.49 782.68,-365.01\"/>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;20 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>19&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M771.17,-310.05C758.61,-269.07 724.91,-178.44 662,-134 652.54,-127.32 635.43,-121.5 614.83,-116.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"615.77,-113.14 605.24,-114.32 614.21,-119.96 615.77,-113.14\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"518.62,-34 373.38,-34 373.38,0 518.62,0 518.62,-34\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"373.38,0 373.38,-34 441.12,-34 441.12,0 373.38,0\"/>\n",
       "<text text-anchor=\"start\" x=\"378.38\" y=\"-19.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"390.75\" y=\"-7.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"441.12,0 441.12,-34 518.62,-34 518.62,0 441.12,0\"/>\n",
       "<text text-anchor=\"start\" x=\"446.12\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 28, 28)</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;21 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>20&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446,-70.28C446,-62.46 446,-53.45 446,-45.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.5,-45.18 446,-35.18 442.5,-45.18 449.5,-45.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2453fa561d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    '''\n",
    "\n",
    "    building block of inception-v1 architecture. creates following 4 branches and concatenate them\n",
    "    (a) branch1: 1x1 conv\n",
    "    (b) branch2: 1x1 conv followed by 3x3 conv\n",
    "    (c) branch3: 1x1 conv followed by 5x5 conv\n",
    "    (d) branch4: Maxpool2d followed by 1x1 conv\n",
    "\n",
    "        Note:\n",
    "            1. output and input feature map height and width should remain the same. Only the channel output should change. eg. 28x28x192 -> 28x28x256\n",
    "            2. To generate same height and width of output feature map as the input feature map, following should be padding for\n",
    "                * 1x1 conv : p=0\n",
    "                * 3x3 conv : p=1\n",
    "                * 5x5 conv : p=2\n",
    "\n",
    "\n",
    "    Args:\n",
    "       in_channels (int) : # of input channels\n",
    "       out_1x1 (int) : number of output channels for branch 1\n",
    "       red_3x3 (int) : reduced 3x3 referring to output channels of 1x1 conv just before 3x3 in branch2\n",
    "       out_3x3 (int) : number of output channels for branch 2\n",
    "       red_5x5 (int) : reduced 5x5 referring to output channels of 1x1 conv just before 5x5 in branch3\n",
    "       out_5x5 (int) : number of output channels for branch 3\n",
    "       out_1x1_pooling (int) : number of output channels for branch 4\n",
    "\n",
    "    Attributes:\n",
    "        concatenated feature maps from all 4 branches constituiting output of Inception module.\n",
    "\n",
    "    '''\n",
    "    def __init__(self , in_channels , out_1x1 , red_3x3 , out_3x3 , red_5x5 , out_5x5 , out_1x1_pooling):\n",
    "        super(InceptionBlock,self).__init__()\n",
    "\n",
    "        # branch1 : k=1,s=1,p=0\n",
    "        self.branch1 = ConvolutionBlock(in_channels,out_1x1,1,1,0)\n",
    "\n",
    "        # branch2 : k=1,s=1,p=0 -> k=3,s=1,p=1\n",
    "        self.branch2 = nn.Sequential(ConvolutionBlock(in_channels,red_3x3,1,1,0),ConvolutionBlock(red_3x3,out_3x3,3,1,1))\n",
    "\n",
    "        # branch3 : k=1,s=1,p=0 -> k=5,s=1,p=2\n",
    "        self.branch3 = nn.Sequential(ConvolutionBlock(in_channels,red_5x5,1,1,0),ConvolutionBlock(red_5x5,out_5x5,5,1,2))\n",
    "\n",
    "        # branch4 : pool(k=3,s=1,p=1) -> k=1,s=1,p=0\n",
    "        self.branch4 = nn.Sequential(nn.MaxPool2d(kernel_size=3,stride=1,padding=1),ConvolutionBlock(in_channels,out_1x1_pooling,1,1,0))\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        # concatenation from dim=1 as dim=0 represents batchsize\n",
    "        return torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],dim=1)\n",
    "\n",
    "\n",
    "def testInceptionBlock():\n",
    "    x = torch.randn((32,192,28,28))\n",
    "    model = InceptionBlock(192,64,96,128,16,32,32)\n",
    "    print(model(x).shape)\n",
    "    return model\n",
    "\n",
    "model = testInceptionBlock()\n",
    "\n",
    "architecture = 'InceptionBlock'\n",
    "model_graph = draw_graph(model, input_size=(1,192,28,28), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
    "model_graph.visual_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IIPBlock(nn.Module):\n",
    "#     def __init__(self, channe):\n",
    "#         super(IIPBlock,self).__init__()\n",
    "\n",
    "\n",
    "class InceptionNetwork(nn.Module):\n",
    "    def __init__(self , in_channels = 1, num_classes = 7, reps = 3):\n",
    "        super(InceptionNetwork,self).__init__()\n",
    "\n",
    "        self.conv1 =  ConvolutionBlock(in_channels,64,3,1,1)\n",
    "        self.conv2 =  ConvolutionBlock(64,128,3,1,1)\n",
    "        \n",
    "        # in_channels , out_1x1 , red_3x3 , out_3x3 , red_5x5 , out_5x5 , out_1x1_pooling\n",
    "        self.inception1 = InceptionBlock(128, 32, 48, 64, 8, 16, 16)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        self.iip_blocks = []\n",
    "\n",
    "        self.iip_blocks.append(InceptionBlock(128, 32, 48, 64, 8, 16, 16))\n",
    "        self.iip_blocks.append(InceptionBlock(128, 64, 96, 128, 16, 32, 32))\n",
    "        self.iip_blocks.append(nn.MaxPool2d(kernel_size=2,stride=2,padding=1))\n",
    "\n",
    "        self.iip_blocks.append(InceptionBlock(256, 64, 96, 128, 16, 32, 32))\n",
    "        self.iip_blocks.append(InceptionBlock(256, 128, 192, 256, 32, 64, 64))\n",
    "        self.iip_blocks.append(nn.MaxPool2d(kernel_size=2,stride=2,padding=1))\n",
    "\n",
    "        self.iip_blocks.append(InceptionBlock(512, 128, 192, 256, 32, 64, 64))\n",
    "        self.iip_blocks.append(InceptionBlock(512, 128, 192, 256, 32, 64, 64))\n",
    "        self.iip_blocks.append(nn.MaxPool2d(kernel_size=4,stride=4,padding=1))\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear( 2048 , num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.inception1(x)\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        for layer in self.iip_blocks:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        flattened = x.view(4, -1)\n",
    "        # print(flattened.shape)\n",
    "        x = self.fc1(flattened)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InceptionNetwork(\n",
       "  (conv1): ConvolutionBlock(\n",
       "    (conv2d): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (conv2): ConvolutionBlock(\n",
       "    (conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (inception1): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testInceptionBlock():\n",
    "    x = torch.randn((4,1,48,48))\n",
    "    model = InceptionNetwork()\n",
    "    print(model(x).shape)\n",
    "    return model\n",
    "\n",
    "testInceptionBlock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 7)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133559\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28709, 1, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.087 | Training Acc: 0.000% (0/4)\n",
      "Training Loss: 2.899 | Training Acc: 15.594% (63/404)\n",
      "Training Loss: 2.855 | Training Acc: 15.050% (121/804)\n",
      "Training Loss: 2.873 | Training Acc: 15.947% (192/1204)\n",
      "Training Loss: 2.890 | Training Acc: 16.085% (258/1604)\n",
      "Training Loss: 2.928 | Training Acc: 16.717% (335/2004)\n",
      "Training Loss: 2.910 | Training Acc: 16.972% (408/2404)\n",
      "Training Loss: 2.943 | Training Acc: 17.297% (485/2804)\n",
      "Training Loss: 2.971 | Training Acc: 17.541% (562/3204)\n",
      "Training Loss: 2.984 | Training Acc: 17.786% (641/3604)\n",
      "Training Loss: 2.991 | Training Acc: 17.682% (708/4004)\n",
      "Training Loss: 3.015 | Training Acc: 17.802% (784/4404)\n",
      "Training Loss: 3.005 | Training Acc: 18.027% (866/4804)\n",
      "Training Loss: 3.028 | Training Acc: 17.948% (934/5204)\n",
      "Training Loss: 3.049 | Training Acc: 17.827% (999/5604)\n",
      "Training Loss: 3.045 | Training Acc: 17.871% (1073/6004)\n",
      "Training Loss: 3.035 | Training Acc: 17.801% (1140/6404)\n",
      "Training Loss: 3.041 | Training Acc: 17.828% (1213/6804)\n",
      "Training Loss: 3.057 | Training Acc: 18.032% (1299/7204)\n",
      "Training Loss: 3.065 | Training Acc: 18.148% (1380/7604)\n",
      "Training Loss: 3.076 | Training Acc: 18.153% (1453/8004)\n",
      "Training Loss: 3.081 | Training Acc: 18.218% (1531/8404)\n",
      "Training Loss: 3.086 | Training Acc: 18.264% (1608/8804)\n",
      "Training Loss: 3.088 | Training Acc: 18.351% (1689/9204)\n",
      "Training Loss: 3.096 | Training Acc: 18.315% (1759/9604)\n",
      "Training Loss: 3.105 | Training Acc: 18.303% (1831/10004)\n",
      "Training Loss: 3.114 | Training Acc: 18.320% (1906/10404)\n",
      "Training Loss: 3.134 | Training Acc: 18.354% (1983/10804)\n",
      "Training Loss: 3.142 | Training Acc: 18.440% (2066/11204)\n",
      "Training Loss: 3.160 | Training Acc: 18.451% (2141/11604)\n",
      "Training Loss: 3.169 | Training Acc: 18.469% (2217/12004)\n",
      "Training Loss: 3.174 | Training Acc: 18.510% (2296/12404)\n",
      "Training Loss: 3.175 | Training Acc: 18.502% (2369/12804)\n",
      "Training Loss: 3.191 | Training Acc: 18.502% (2443/13204)\n",
      "Training Loss: 3.188 | Training Acc: 18.656% (2538/13604)\n",
      "Training Loss: 3.187 | Training Acc: 18.695% (2618/14004)\n",
      "Training Loss: 3.200 | Training Acc: 18.800% (2708/14404)\n",
      "Training Loss: 3.214 | Training Acc: 18.738% (2774/14804)\n",
      "Training Loss: 3.216 | Training Acc: 18.831% (2863/15204)\n",
      "Training Loss: 3.224 | Training Acc: 18.796% (2933/15604)\n",
      "Training Loss: 3.231 | Training Acc: 18.739% (2999/16004)\n",
      "Training Loss: 3.233 | Training Acc: 18.721% (3071/16404)\n",
      "Training Loss: 3.248 | Training Acc: 18.740% (3149/16804)\n",
      "Training Loss: 3.248 | Training Acc: 18.746% (3225/17204)\n",
      "Training Loss: 3.264 | Training Acc: 18.757% (3302/17604)\n",
      "Training Loss: 3.271 | Training Acc: 18.724% (3371/18004)\n",
      "Training Loss: 3.273 | Training Acc: 18.740% (3449/18404)\n",
      "Training Loss: 3.280 | Training Acc: 18.783% (3532/18804)\n",
      "Training Loss: 3.279 | Training Acc: 18.788% (3608/19204)\n",
      "Training Loss: 3.283 | Training Acc: 18.818% (3689/19604)\n",
      "Training Loss: 3.282 | Training Acc: 18.801% (3761/20004)\n",
      "Training Loss: 3.286 | Training Acc: 18.766% (3829/20404)\n",
      "Training Loss: 3.285 | Training Acc: 18.857% (3923/20804)\n",
      "Training Loss: 3.293 | Training Acc: 18.822% (3991/21204)\n",
      "Training Loss: 3.298 | Training Acc: 18.853% (4073/21604)\n",
      "Training Loss: 3.300 | Training Acc: 18.897% (4158/22004)\n",
      "Training Loss: 3.302 | Training Acc: 18.921% (4239/22404)\n",
      "Training Loss: 3.300 | Training Acc: 19.023% (4338/22804)\n",
      "Training Loss: 3.297 | Training Acc: 19.044% (4419/23204)\n",
      "Training Loss: 3.304 | Training Acc: 19.026% (4491/23604)\n",
      "Training Loss: 3.304 | Training Acc: 19.034% (4569/24004)\n",
      "Training Loss: 3.304 | Training Acc: 19.087% (4658/24404)\n",
      "Training Loss: 3.305 | Training Acc: 19.090% (4735/24804)\n",
      "Training Loss: 3.310 | Training Acc: 19.100% (4814/25204)\n",
      "Training Loss: 3.312 | Training Acc: 19.126% (4897/25604)\n",
      "Training Loss: 3.318 | Training Acc: 19.136% (4976/26004)\n",
      "Training Loss: 3.322 | Training Acc: 19.152% (5057/26404)\n",
      "Training Loss: 3.321 | Training Acc: 19.135% (5129/26804)\n",
      "Training Loss: 3.322 | Training Acc: 19.155% (5211/27204)\n",
      "Training Loss: 3.322 | Training Acc: 19.149% (5286/27604)\n",
      "Training Loss: 3.324 | Training Acc: 19.147% (5362/28004)\n",
      "Training Loss: 3.332 | Training Acc: 19.166% (5444/28404)\n",
      "Results after epoch 1\n",
      "Training Loss: 3.328 | Training Acc: 19.232% (5521/28708)\n",
      "Training Loss: 3.345 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 3.753 | Training Acc: 17.822% (72/404)\n",
      "Training Loss: 3.603 | Training Acc: 18.284% (147/804)\n",
      "Training Loss: 3.589 | Training Acc: 18.272% (220/1204)\n",
      "Training Loss: 3.474 | Training Acc: 19.576% (314/1604)\n",
      "Training Loss: 3.495 | Training Acc: 19.711% (395/2004)\n",
      "Training Loss: 3.491 | Training Acc: 19.260% (463/2404)\n",
      "Training Loss: 3.450 | Training Acc: 19.757% (554/2804)\n",
      "Training Loss: 3.476 | Training Acc: 19.725% (632/3204)\n",
      "Training Loss: 3.506 | Training Acc: 19.673% (709/3604)\n",
      "Training Loss: 3.495 | Training Acc: 19.555% (783/4004)\n",
      "Training Loss: 3.490 | Training Acc: 19.369% (853/4404)\n",
      "Training Loss: 3.485 | Training Acc: 19.692% (946/4804)\n",
      "Training Loss: 3.532 | Training Acc: 19.639% (1022/5204)\n",
      "Training Loss: 3.509 | Training Acc: 19.700% (1104/5604)\n",
      "Training Loss: 3.497 | Training Acc: 19.620% (1178/6004)\n",
      "Training Loss: 3.506 | Training Acc: 19.347% (1239/6404)\n",
      "Training Loss: 3.498 | Training Acc: 19.400% (1320/6804)\n",
      "Training Loss: 3.480 | Training Acc: 19.684% (1418/7204)\n",
      "Training Loss: 3.482 | Training Acc: 19.503% (1483/7604)\n",
      "Training Loss: 3.482 | Training Acc: 19.690% (1576/8004)\n",
      "Training Loss: 3.471 | Training Acc: 19.741% (1659/8404)\n",
      "Training Loss: 3.482 | Training Acc: 19.650% (1730/8804)\n",
      "Training Loss: 3.485 | Training Acc: 19.676% (1811/9204)\n",
      "Training Loss: 3.475 | Training Acc: 19.690% (1891/9604)\n",
      "Training Loss: 3.477 | Training Acc: 19.692% (1970/10004)\n",
      "Training Loss: 3.485 | Training Acc: 19.646% (2044/10404)\n",
      "Training Loss: 3.488 | Training Acc: 19.641% (2122/10804)\n",
      "Training Loss: 3.487 | Training Acc: 19.663% (2203/11204)\n",
      "Training Loss: 3.486 | Training Acc: 19.683% (2284/11604)\n",
      "Training Loss: 3.489 | Training Acc: 19.693% (2364/12004)\n",
      "Training Loss: 3.492 | Training Acc: 19.711% (2445/12404)\n",
      "Training Loss: 3.495 | Training Acc: 19.783% (2533/12804)\n",
      "Training Loss: 3.489 | Training Acc: 19.873% (2624/13204)\n",
      "Training Loss: 3.492 | Training Acc: 19.891% (2706/13604)\n",
      "Training Loss: 3.493 | Training Acc: 19.966% (2796/14004)\n",
      "Training Loss: 3.489 | Training Acc: 19.946% (2873/14404)\n",
      "Training Loss: 3.489 | Training Acc: 19.914% (2948/14804)\n",
      "Training Loss: 3.486 | Training Acc: 19.936% (3031/15204)\n",
      "Training Loss: 3.486 | Training Acc: 19.873% (3101/15604)\n",
      "Training Loss: 3.486 | Training Acc: 19.958% (3194/16004)\n",
      "Training Loss: 3.492 | Training Acc: 19.867% (3259/16404)\n",
      "Training Loss: 3.490 | Training Acc: 19.793% (3326/16804)\n",
      "Training Loss: 3.488 | Training Acc: 19.786% (3404/17204)\n",
      "Training Loss: 3.494 | Training Acc: 19.774% (3481/17604)\n",
      "Training Loss: 3.488 | Training Acc: 19.879% (3579/18004)\n",
      "Training Loss: 3.487 | Training Acc: 19.887% (3660/18404)\n",
      "Training Loss: 3.495 | Training Acc: 19.916% (3745/18804)\n",
      "Training Loss: 3.494 | Training Acc: 19.897% (3821/19204)\n",
      "Training Loss: 3.501 | Training Acc: 19.828% (3887/19604)\n",
      "Training Loss: 3.501 | Training Acc: 19.836% (3968/20004)\n",
      "Training Loss: 3.503 | Training Acc: 19.771% (4034/20404)\n",
      "Training Loss: 3.507 | Training Acc: 19.708% (4100/20804)\n",
      "Training Loss: 3.511 | Training Acc: 19.694% (4176/21204)\n",
      "Training Loss: 3.505 | Training Acc: 19.691% (4254/21604)\n",
      "Training Loss: 3.506 | Training Acc: 19.692% (4333/22004)\n",
      "Training Loss: 3.502 | Training Acc: 19.751% (4425/22404)\n",
      "Training Loss: 3.502 | Training Acc: 19.795% (4514/22804)\n",
      "Training Loss: 3.499 | Training Acc: 19.872% (4611/23204)\n",
      "Training Loss: 3.499 | Training Acc: 19.870% (4690/23604)\n",
      "Training Loss: 3.498 | Training Acc: 19.913% (4780/24004)\n",
      "Training Loss: 3.495 | Training Acc: 19.931% (4864/24404)\n",
      "Training Loss: 3.489 | Training Acc: 19.908% (4938/24804)\n",
      "Training Loss: 3.487 | Training Acc: 19.965% (5032/25204)\n",
      "Training Loss: 3.486 | Training Acc: 20.005% (5122/25604)\n",
      "Training Loss: 3.481 | Training Acc: 19.997% (5200/26004)\n",
      "Training Loss: 3.483 | Training Acc: 19.967% (5272/26404)\n",
      "Training Loss: 3.483 | Training Acc: 19.971% (5353/26804)\n",
      "Training Loss: 3.480 | Training Acc: 19.982% (5436/27204)\n",
      "Training Loss: 3.482 | Training Acc: 19.954% (5508/27604)\n",
      "Training Loss: 3.482 | Training Acc: 19.947% (5586/28004)\n",
      "Training Loss: 3.487 | Training Acc: 19.906% (5654/28404)\n",
      "Results after epoch 2\n",
      "Training Loss: 3.488 | Training Acc: 19.876% (5706/28708)\n",
      "Training Loss: 2.279 | Training Acc: 25.000% (1/4)\n",
      "Training Loss: 3.638 | Training Acc: 17.574% (71/404)\n",
      "Training Loss: 3.577 | Training Acc: 17.662% (142/804)\n",
      "Training Loss: 3.582 | Training Acc: 19.020% (229/1204)\n",
      "Training Loss: 3.621 | Training Acc: 18.454% (296/1604)\n",
      "Training Loss: 3.668 | Training Acc: 18.064% (362/2004)\n",
      "Training Loss: 3.685 | Training Acc: 17.887% (430/2404)\n",
      "Training Loss: 3.686 | Training Acc: 17.689% (496/2804)\n",
      "Training Loss: 3.666 | Training Acc: 18.071% (579/3204)\n",
      "Training Loss: 3.633 | Training Acc: 18.313% (660/3604)\n",
      "Training Loss: 3.651 | Training Acc: 18.581% (744/4004)\n",
      "Training Loss: 3.632 | Training Acc: 18.824% (829/4404)\n",
      "Training Loss: 3.628 | Training Acc: 18.651% (896/4804)\n",
      "Training Loss: 3.600 | Training Acc: 18.947% (986/5204)\n",
      "Training Loss: 3.605 | Training Acc: 18.772% (1052/5604)\n",
      "Training Loss: 3.602 | Training Acc: 18.654% (1120/6004)\n",
      "Training Loss: 3.592 | Training Acc: 18.848% (1207/6404)\n",
      "Training Loss: 3.603 | Training Acc: 18.768% (1277/6804)\n",
      "Training Loss: 3.604 | Training Acc: 18.629% (1342/7204)\n",
      "Training Loss: 3.602 | Training Acc: 18.346% (1395/7604)\n",
      "Training Loss: 3.589 | Training Acc: 18.466% (1478/8004)\n",
      "Training Loss: 3.598 | Training Acc: 18.408% (1547/8404)\n",
      "Training Loss: 3.597 | Training Acc: 18.469% (1626/8804)\n",
      "Training Loss: 3.593 | Training Acc: 18.590% (1711/9204)\n",
      "Training Loss: 3.581 | Training Acc: 18.680% (1794/9604)\n",
      "Training Loss: 3.591 | Training Acc: 18.593% (1860/10004)\n",
      "Training Loss: 3.580 | Training Acc: 18.800% (1956/10404)\n",
      "Training Loss: 3.573 | Training Acc: 18.863% (2038/10804)\n",
      "Training Loss: 3.561 | Training Acc: 19.002% (2129/11204)\n",
      "Training Loss: 3.570 | Training Acc: 19.019% (2207/11604)\n",
      "Training Loss: 3.567 | Training Acc: 19.060% (2288/12004)\n",
      "Training Loss: 3.566 | Training Acc: 19.050% (2363/12404)\n",
      "Training Loss: 3.568 | Training Acc: 19.010% (2434/12804)\n",
      "Training Loss: 3.565 | Training Acc: 19.093% (2521/13204)\n",
      "Training Loss: 3.565 | Training Acc: 19.039% (2590/13604)\n",
      "Training Loss: 3.556 | Training Acc: 19.066% (2670/14004)\n",
      "Training Loss: 3.558 | Training Acc: 19.016% (2739/14404)\n",
      "Training Loss: 3.556 | Training Acc: 19.123% (2831/14804)\n",
      "Training Loss: 3.550 | Training Acc: 19.107% (2905/15204)\n",
      "Training Loss: 3.546 | Training Acc: 19.149% (2988/15604)\n",
      "Training Loss: 3.547 | Training Acc: 19.151% (3065/16004)\n",
      "Training Loss: 3.549 | Training Acc: 19.190% (3148/16404)\n",
      "Training Loss: 3.551 | Training Acc: 19.204% (3227/16804)\n",
      "Training Loss: 3.556 | Training Acc: 19.141% (3293/17204)\n",
      "Training Loss: 3.556 | Training Acc: 19.052% (3354/17604)\n",
      "Training Loss: 3.563 | Training Acc: 19.035% (3427/18004)\n",
      "Training Loss: 3.564 | Training Acc: 19.099% (3515/18404)\n",
      "Training Loss: 3.561 | Training Acc: 19.182% (3607/18804)\n",
      "Training Loss: 3.558 | Training Acc: 19.210% (3689/19204)\n",
      "Training Loss: 3.557 | Training Acc: 19.266% (3777/19604)\n",
      "Training Loss: 3.554 | Training Acc: 19.291% (3859/20004)\n",
      "Training Loss: 3.550 | Training Acc: 19.349% (3948/20404)\n",
      "Training Loss: 3.546 | Training Acc: 19.424% (4041/20804)\n",
      "Training Loss: 3.549 | Training Acc: 19.482% (4131/21204)\n",
      "Training Loss: 3.549 | Training Acc: 19.496% (4212/21604)\n",
      "Training Loss: 3.550 | Training Acc: 19.510% (4293/22004)\n",
      "Training Loss: 3.549 | Training Acc: 19.541% (4378/22404)\n",
      "Training Loss: 3.547 | Training Acc: 19.501% (4447/22804)\n",
      "Training Loss: 3.545 | Training Acc: 19.510% (4527/23204)\n",
      "Training Loss: 3.546 | Training Acc: 19.556% (4616/23604)\n",
      "Training Loss: 3.542 | Training Acc: 19.588% (4702/24004)\n",
      "Training Loss: 3.543 | Training Acc: 19.550% (4771/24404)\n",
      "Training Loss: 3.538 | Training Acc: 19.606% (4863/24804)\n",
      "Training Loss: 3.541 | Training Acc: 19.612% (4943/25204)\n",
      "Training Loss: 3.547 | Training Acc: 19.618% (5023/25604)\n",
      "Training Loss: 3.546 | Training Acc: 19.643% (5108/26004)\n",
      "Training Loss: 3.548 | Training Acc: 19.649% (5188/26404)\n",
      "Training Loss: 3.548 | Training Acc: 19.658% (5269/26804)\n",
      "Training Loss: 3.544 | Training Acc: 19.696% (5358/27204)\n",
      "Training Loss: 3.547 | Training Acc: 19.678% (5432/27604)\n",
      "Training Loss: 3.546 | Training Acc: 19.679% (5511/28004)\n",
      "Training Loss: 3.550 | Training Acc: 19.638% (5578/28404)\n",
      "Results after epoch 3\n",
      "Training Loss: 3.548 | Training Acc: 19.615% (5631/28708)\n",
      "Training Loss: 4.718 | Training Acc: 0.000% (0/4)\n",
      "Training Loss: 3.292 | Training Acc: 24.752% (100/404)\n",
      "Training Loss: 3.396 | Training Acc: 24.005% (193/804)\n",
      "Training Loss: 3.455 | Training Acc: 22.259% (268/1204)\n",
      "Training Loss: 3.456 | Training Acc: 21.945% (352/1604)\n",
      "Training Loss: 3.414 | Training Acc: 20.958% (420/2004)\n",
      "Training Loss: 3.484 | Training Acc: 20.757% (499/2404)\n",
      "Training Loss: 3.486 | Training Acc: 20.827% (584/2804)\n",
      "Training Loss: 3.534 | Training Acc: 20.880% (669/3204)\n",
      "Training Loss: 3.517 | Training Acc: 20.699% (746/3604)\n",
      "Training Loss: 3.503 | Training Acc: 20.729% (830/4004)\n",
      "Training Loss: 3.506 | Training Acc: 20.413% (899/4404)\n",
      "Training Loss: 3.516 | Training Acc: 20.337% (977/4804)\n",
      "Training Loss: 3.506 | Training Acc: 20.311% (1057/5204)\n",
      "Training Loss: 3.496 | Training Acc: 20.521% (1150/5604)\n",
      "Training Loss: 3.470 | Training Acc: 20.553% (1234/6004)\n",
      "Training Loss: 3.477 | Training Acc: 20.472% (1311/6404)\n",
      "Training Loss: 3.496 | Training Acc: 20.209% (1375/6804)\n",
      "Training Loss: 3.494 | Training Acc: 20.128% (1450/7204)\n",
      "Training Loss: 3.504 | Training Acc: 19.937% (1516/7604)\n",
      "Training Loss: 3.506 | Training Acc: 19.853% (1589/8004)\n",
      "Training Loss: 3.516 | Training Acc: 19.764% (1661/8404)\n",
      "Training Loss: 3.516 | Training Acc: 19.673% (1732/8804)\n",
      "Training Loss: 3.517 | Training Acc: 19.589% (1803/9204)\n",
      "Training Loss: 3.508 | Training Acc: 19.690% (1891/9604)\n",
      "Training Loss: 3.505 | Training Acc: 19.792% (1980/10004)\n",
      "Training Loss: 3.499 | Training Acc: 19.944% (2075/10404)\n",
      "Training Loss: 3.495 | Training Acc: 20.057% (2167/10804)\n",
      "Training Loss: 3.493 | Training Acc: 20.109% (2253/11204)\n",
      "Training Loss: 3.493 | Training Acc: 20.097% (2332/11604)\n",
      "Training Loss: 3.507 | Training Acc: 20.035% (2405/12004)\n",
      "Training Loss: 3.501 | Training Acc: 20.171% (2502/12404)\n",
      "Training Loss: 3.501 | Training Acc: 20.173% (2583/12804)\n",
      "Training Loss: 3.498 | Training Acc: 20.221% (2670/13204)\n",
      "Training Loss: 3.496 | Training Acc: 20.303% (2762/13604)\n",
      "Training Loss: 3.498 | Training Acc: 20.373% (2853/14004)\n",
      "Training Loss: 3.490 | Training Acc: 20.432% (2943/14404)\n",
      "Training Loss: 3.488 | Training Acc: 20.528% (3039/14804)\n",
      "Training Loss: 3.491 | Training Acc: 20.508% (3118/15204)\n",
      "Training Loss: 3.499 | Training Acc: 20.559% (3208/15604)\n",
      "Training Loss: 3.508 | Training Acc: 20.451% (3273/16004)\n",
      "Training Loss: 3.517 | Training Acc: 20.477% (3359/16404)\n",
      "Training Loss: 3.524 | Training Acc: 20.495% (3444/16804)\n",
      "Training Loss: 3.523 | Training Acc: 20.449% (3518/17204)\n",
      "Training Loss: 3.523 | Training Acc: 20.490% (3607/17604)\n",
      "Training Loss: 3.520 | Training Acc: 20.434% (3679/18004)\n",
      "Training Loss: 3.517 | Training Acc: 20.425% (3759/18404)\n",
      "Training Loss: 3.521 | Training Acc: 20.395% (3835/18804)\n",
      "Training Loss: 3.525 | Training Acc: 20.412% (3920/19204)\n",
      "Training Loss: 3.525 | Training Acc: 20.414% (4002/19604)\n",
      "Training Loss: 3.523 | Training Acc: 20.411% (4083/20004)\n",
      "Training Loss: 3.524 | Training Acc: 20.398% (4162/20404)\n",
      "Training Loss: 3.527 | Training Acc: 20.361% (4236/20804)\n",
      "Training Loss: 3.524 | Training Acc: 20.341% (4313/21204)\n",
      "Training Loss: 3.526 | Training Acc: 20.293% (4384/21604)\n",
      "Training Loss: 3.532 | Training Acc: 20.169% (4438/22004)\n",
      "Training Loss: 3.533 | Training Acc: 20.157% (4516/22404)\n",
      "Training Loss: 3.530 | Training Acc: 20.128% (4590/22804)\n",
      "Training Loss: 3.535 | Training Acc: 20.143% (4674/23204)\n",
      "Training Loss: 3.542 | Training Acc: 20.086% (4741/23604)\n",
      "Training Loss: 3.541 | Training Acc: 20.101% (4825/24004)\n",
      "Training Loss: 3.544 | Training Acc: 20.054% (4894/24404)\n",
      "Training Loss: 3.540 | Training Acc: 20.077% (4980/24804)\n",
      "Training Loss: 3.541 | Training Acc: 20.120% (5071/25204)\n",
      "Training Loss: 3.542 | Training Acc: 20.126% (5153/25604)\n",
      "Training Loss: 3.542 | Training Acc: 20.128% (5234/26004)\n",
      "Training Loss: 3.542 | Training Acc: 20.152% (5321/26404)\n",
      "Training Loss: 3.541 | Training Acc: 20.154% (5402/26804)\n",
      "Training Loss: 3.536 | Training Acc: 20.207% (5497/27204)\n",
      "Training Loss: 3.537 | Training Acc: 20.164% (5566/27604)\n",
      "Training Loss: 3.536 | Training Acc: 20.154% (5644/28004)\n",
      "Training Loss: 3.536 | Training Acc: 20.198% (5737/28404)\n",
      "Results after epoch 4\n",
      "Training Loss: 3.536 | Training Acc: 20.183% (5794/28708)\n",
      "Training Loss: 2.462 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 3.401 | Training Acc: 20.297% (82/404)\n",
      "Training Loss: 3.435 | Training Acc: 19.652% (158/804)\n",
      "Training Loss: 3.389 | Training Acc: 19.684% (237/1204)\n",
      "Training Loss: 3.490 | Training Acc: 19.264% (309/1604)\n",
      "Training Loss: 3.457 | Training Acc: 19.112% (383/2004)\n",
      "Training Loss: 3.433 | Training Acc: 19.967% (480/2404)\n",
      "Training Loss: 3.443 | Training Acc: 19.864% (557/2804)\n",
      "Training Loss: 3.465 | Training Acc: 20.256% (649/3204)\n",
      "Training Loss: 3.439 | Training Acc: 20.560% (741/3604)\n",
      "Training Loss: 3.452 | Training Acc: 20.330% (814/4004)\n",
      "Training Loss: 3.445 | Training Acc: 20.436% (900/4404)\n",
      "Training Loss: 3.445 | Training Acc: 20.379% (979/4804)\n",
      "Training Loss: 3.454 | Training Acc: 20.311% (1057/5204)\n",
      "Training Loss: 3.476 | Training Acc: 20.396% (1143/5604)\n",
      "Training Loss: 3.476 | Training Acc: 20.336% (1221/6004)\n",
      "Training Loss: 3.479 | Training Acc: 20.237% (1296/6404)\n",
      "Training Loss: 3.471 | Training Acc: 20.400% (1388/6804)\n",
      "Training Loss: 3.497 | Training Acc: 20.211% (1456/7204)\n",
      "Training Loss: 3.503 | Training Acc: 20.003% (1521/7604)\n",
      "Training Loss: 3.503 | Training Acc: 20.140% (1612/8004)\n",
      "Training Loss: 3.500 | Training Acc: 20.217% (1699/8404)\n",
      "Training Loss: 3.488 | Training Acc: 20.229% (1781/8804)\n",
      "Training Loss: 3.472 | Training Acc: 20.361% (1874/9204)\n",
      "Training Loss: 3.466 | Training Acc: 20.512% (1970/9604)\n",
      "Training Loss: 3.459 | Training Acc: 20.562% (2057/10004)\n",
      "Training Loss: 3.474 | Training Acc: 20.483% (2131/10404)\n",
      "Training Loss: 3.491 | Training Acc: 20.400% (2204/10804)\n",
      "Training Loss: 3.491 | Training Acc: 20.555% (2303/11204)\n",
      "Training Loss: 3.501 | Training Acc: 20.441% (2372/11604)\n",
      "Training Loss: 3.508 | Training Acc: 20.418% (2451/12004)\n",
      "Training Loss: 3.501 | Training Acc: 20.485% (2541/12404)\n",
      "Training Loss: 3.505 | Training Acc: 20.462% (2620/12804)\n",
      "Training Loss: 3.508 | Training Acc: 20.486% (2705/13204)\n",
      "Training Loss: 3.505 | Training Acc: 20.479% (2786/13604)\n",
      "Training Loss: 3.506 | Training Acc: 20.373% (2853/14004)\n",
      "Training Loss: 3.508 | Training Acc: 20.258% (2918/14404)\n",
      "Training Loss: 3.503 | Training Acc: 20.278% (3002/14804)\n",
      "Training Loss: 3.501 | Training Acc: 20.291% (3085/15204)\n",
      "Training Loss: 3.499 | Training Acc: 20.277% (3164/15604)\n",
      "Training Loss: 3.501 | Training Acc: 20.232% (3238/16004)\n",
      "Training Loss: 3.499 | Training Acc: 20.251% (3322/16404)\n",
      "Training Loss: 3.496 | Training Acc: 20.358% (3421/16804)\n",
      "Training Loss: 3.497 | Training Acc: 20.327% (3497/17204)\n",
      "Training Loss: 3.500 | Training Acc: 20.251% (3565/17604)\n",
      "Training Loss: 3.508 | Training Acc: 20.246% (3645/18004)\n",
      "Training Loss: 3.507 | Training Acc: 20.256% (3728/18404)\n",
      "Training Loss: 3.511 | Training Acc: 20.208% (3800/18804)\n",
      "Training Loss: 3.505 | Training Acc: 20.256% (3890/19204)\n",
      "Training Loss: 3.503 | Training Acc: 20.302% (3980/19604)\n",
      "Training Loss: 3.500 | Training Acc: 20.271% (4055/20004)\n",
      "Training Loss: 3.505 | Training Acc: 20.275% (4137/20404)\n",
      "Training Loss: 3.501 | Training Acc: 20.333% (4230/20804)\n",
      "Training Loss: 3.502 | Training Acc: 20.326% (4310/21204)\n",
      "Training Loss: 3.501 | Training Acc: 20.362% (4399/21604)\n",
      "Training Loss: 3.506 | Training Acc: 20.305% (4468/22004)\n",
      "Training Loss: 3.503 | Training Acc: 20.313% (4551/22404)\n",
      "Training Loss: 3.505 | Training Acc: 20.330% (4636/22804)\n",
      "Training Loss: 3.506 | Training Acc: 20.346% (4721/23204)\n",
      "Training Loss: 3.507 | Training Acc: 20.352% (4804/23604)\n",
      "Training Loss: 3.506 | Training Acc: 20.363% (4888/24004)\n",
      "Training Loss: 3.509 | Training Acc: 20.398% (4978/24404)\n",
      "Training Loss: 3.505 | Training Acc: 20.444% (5071/24804)\n",
      "Training Loss: 3.505 | Training Acc: 20.429% (5149/25204)\n",
      "Training Loss: 3.505 | Training Acc: 20.434% (5232/25604)\n",
      "Training Loss: 3.509 | Training Acc: 20.462% (5321/26004)\n",
      "Training Loss: 3.506 | Training Acc: 20.478% (5407/26404)\n",
      "Training Loss: 3.507 | Training Acc: 20.497% (5494/26804)\n",
      "Training Loss: 3.506 | Training Acc: 20.490% (5574/27204)\n",
      "Training Loss: 3.504 | Training Acc: 20.526% (5666/27604)\n",
      "Training Loss: 3.506 | Training Acc: 20.483% (5736/28004)\n",
      "Training Loss: 3.501 | Training Acc: 20.550% (5837/28404)\n",
      "Results after epoch 5\n",
      "Training Loss: 3.500 | Training Acc: 20.590% (5911/28708)\n",
      "Training Loss: 4.569 | Training Acc: 25.000% (1/4)\n",
      "Training Loss: 3.685 | Training Acc: 19.554% (79/404)\n",
      "Training Loss: 3.718 | Training Acc: 18.532% (149/804)\n",
      "Training Loss: 3.656 | Training Acc: 20.432% (246/1204)\n",
      "Training Loss: 3.648 | Training Acc: 20.511% (329/1604)\n",
      "Training Loss: 3.595 | Training Acc: 20.808% (417/2004)\n",
      "Training Loss: 3.566 | Training Acc: 20.882% (502/2404)\n",
      "Training Loss: 3.554 | Training Acc: 20.827% (584/2804)\n",
      "Training Loss: 3.516 | Training Acc: 20.849% (668/3204)\n",
      "Training Loss: 3.517 | Training Acc: 20.727% (747/3604)\n",
      "Training Loss: 3.510 | Training Acc: 20.679% (828/4004)\n",
      "Training Loss: 3.496 | Training Acc: 20.913% (921/4404)\n",
      "Training Loss: 3.505 | Training Acc: 20.816% (1000/4804)\n",
      "Training Loss: 3.496 | Training Acc: 20.888% (1087/5204)\n",
      "Training Loss: 3.515 | Training Acc: 20.735% (1162/5604)\n",
      "Training Loss: 3.539 | Training Acc: 20.703% (1243/6004)\n",
      "Training Loss: 3.551 | Training Acc: 20.565% (1317/6404)\n",
      "Training Loss: 3.564 | Training Acc: 20.620% (1403/6804)\n",
      "Training Loss: 3.559 | Training Acc: 20.600% (1484/7204)\n",
      "Training Loss: 3.550 | Training Acc: 20.647% (1570/7604)\n",
      "Training Loss: 3.553 | Training Acc: 20.527% (1643/8004)\n",
      "Training Loss: 3.572 | Training Acc: 20.407% (1715/8404)\n",
      "Training Loss: 3.574 | Training Acc: 20.388% (1795/8804)\n",
      "Training Loss: 3.573 | Training Acc: 20.372% (1875/9204)\n",
      "Training Loss: 3.568 | Training Acc: 20.419% (1961/9604)\n",
      "Training Loss: 3.561 | Training Acc: 20.382% (2039/10004)\n",
      "Training Loss: 3.566 | Training Acc: 20.348% (2117/10404)\n",
      "Training Loss: 3.572 | Training Acc: 20.418% (2206/10804)\n",
      "Training Loss: 3.572 | Training Acc: 20.314% (2276/11204)\n",
      "Training Loss: 3.567 | Training Acc: 20.260% (2351/11604)\n",
      "Training Loss: 3.570 | Training Acc: 20.127% (2416/12004)\n",
      "Training Loss: 3.569 | Training Acc: 20.066% (2489/12404)\n",
      "Training Loss: 3.580 | Training Acc: 19.900% (2548/12804)\n",
      "Training Loss: 3.585 | Training Acc: 19.933% (2632/13204)\n",
      "Training Loss: 3.583 | Training Acc: 19.869% (2703/13604)\n",
      "Training Loss: 3.577 | Training Acc: 19.937% (2792/14004)\n",
      "Training Loss: 3.568 | Training Acc: 19.981% (2878/14404)\n",
      "Training Loss: 3.556 | Training Acc: 20.015% (2963/14804)\n",
      "Training Loss: 3.556 | Training Acc: 20.001% (3041/15204)\n",
      "Training Loss: 3.559 | Training Acc: 19.969% (3116/15604)\n",
      "Training Loss: 3.558 | Training Acc: 19.983% (3198/16004)\n",
      "Training Loss: 3.565 | Training Acc: 20.062% (3291/16404)\n",
      "Training Loss: 3.564 | Training Acc: 19.960% (3354/16804)\n",
      "Training Loss: 3.561 | Training Acc: 19.966% (3435/17204)\n",
      "Training Loss: 3.555 | Training Acc: 19.984% (3518/17604)\n",
      "Training Loss: 3.553 | Training Acc: 20.029% (3606/18004)\n",
      "Training Loss: 3.557 | Training Acc: 19.941% (3670/18404)\n",
      "Training Loss: 3.556 | Training Acc: 19.969% (3755/18804)\n",
      "Training Loss: 3.560 | Training Acc: 19.928% (3827/19204)\n",
      "Training Loss: 3.557 | Training Acc: 19.945% (3910/19604)\n",
      "Training Loss: 3.552 | Training Acc: 19.946% (3990/20004)\n",
      "Training Loss: 3.545 | Training Acc: 20.079% (4097/20404)\n",
      "Training Loss: 3.542 | Training Acc: 20.126% (4187/20804)\n",
      "Training Loss: 3.541 | Training Acc: 20.180% (4279/21204)\n",
      "Training Loss: 3.542 | Training Acc: 20.191% (4362/21604)\n",
      "Training Loss: 3.541 | Training Acc: 20.255% (4457/22004)\n",
      "Training Loss: 3.541 | Training Acc: 20.246% (4536/22404)\n",
      "Training Loss: 3.538 | Training Acc: 20.286% (4626/22804)\n",
      "Training Loss: 3.542 | Training Acc: 20.281% (4706/23204)\n",
      "Training Loss: 3.541 | Training Acc: 20.225% (4774/23604)\n",
      "Training Loss: 3.547 | Training Acc: 20.222% (4854/24004)\n",
      "Training Loss: 3.545 | Training Acc: 20.263% (4945/24404)\n",
      "Training Loss: 3.546 | Training Acc: 20.259% (5025/24804)\n",
      "Training Loss: 3.548 | Training Acc: 20.275% (5110/25204)\n",
      "Training Loss: 3.546 | Training Acc: 20.262% (5188/25604)\n",
      "Training Loss: 3.547 | Training Acc: 20.297% (5278/26004)\n",
      "Training Loss: 3.549 | Training Acc: 20.262% (5350/26404)\n",
      "Training Loss: 3.547 | Training Acc: 20.288% (5438/26804)\n",
      "Training Loss: 3.549 | Training Acc: 20.310% (5525/27204)\n",
      "Training Loss: 3.549 | Training Acc: 20.359% (5620/27604)\n",
      "Training Loss: 3.551 | Training Acc: 20.386% (5709/28004)\n",
      "Training Loss: 3.547 | Training Acc: 20.399% (5794/28404)\n",
      "Results after epoch 6\n",
      "Training Loss: 3.549 | Training Acc: 20.357% (5844/28708)\n",
      "Training Loss: 2.116 | Training Acc: 0.000% (0/4)\n",
      "Training Loss: 3.331 | Training Acc: 22.277% (90/404)\n",
      "Training Loss: 3.396 | Training Acc: 23.259% (187/804)\n",
      "Training Loss: 3.410 | Training Acc: 22.674% (273/1204)\n",
      "Training Loss: 3.415 | Training Acc: 22.319% (358/1604)\n",
      "Training Loss: 3.459 | Training Acc: 22.305% (447/2004)\n",
      "Training Loss: 3.472 | Training Acc: 21.922% (527/2404)\n",
      "Training Loss: 3.478 | Training Acc: 22.004% (617/2804)\n",
      "Training Loss: 3.510 | Training Acc: 21.879% (701/3204)\n",
      "Training Loss: 3.494 | Training Acc: 21.781% (785/3604)\n",
      "Training Loss: 3.513 | Training Acc: 21.653% (867/4004)\n",
      "Training Loss: 3.526 | Training Acc: 21.549% (949/4404)\n",
      "Training Loss: 3.534 | Training Acc: 21.378% (1027/4804)\n",
      "Training Loss: 3.535 | Training Acc: 21.522% (1120/5204)\n",
      "Training Loss: 3.527 | Training Acc: 21.413% (1200/5604)\n",
      "Training Loss: 3.512 | Training Acc: 21.369% (1283/6004)\n",
      "Training Loss: 3.482 | Training Acc: 21.487% (1376/6404)\n",
      "Training Loss: 3.522 | Training Acc: 21.179% (1441/6804)\n",
      "Training Loss: 3.519 | Training Acc: 21.127% (1522/7204)\n",
      "Training Loss: 3.523 | Training Acc: 21.068% (1602/7604)\n",
      "Training Loss: 3.519 | Training Acc: 20.977% (1679/8004)\n",
      "Training Loss: 3.514 | Training Acc: 20.847% (1752/8404)\n",
      "Training Loss: 3.514 | Training Acc: 20.820% (1833/8804)\n",
      "Training Loss: 3.515 | Training Acc: 20.871% (1921/9204)\n",
      "Training Loss: 3.515 | Training Acc: 20.752% (1993/9604)\n",
      "Training Loss: 3.516 | Training Acc: 20.492% (2050/10004)\n",
      "Training Loss: 3.520 | Training Acc: 20.463% (2129/10404)\n",
      "Training Loss: 3.514 | Training Acc: 20.474% (2212/10804)\n",
      "Training Loss: 3.520 | Training Acc: 20.439% (2290/11204)\n",
      "Training Loss: 3.524 | Training Acc: 20.519% (2381/11604)\n",
      "Training Loss: 3.538 | Training Acc: 20.493% (2460/12004)\n",
      "Training Loss: 3.552 | Training Acc: 20.348% (2524/12404)\n",
      "Training Loss: 3.545 | Training Acc: 20.322% (2602/12804)\n",
      "Training Loss: 3.545 | Training Acc: 20.214% (2669/13204)\n",
      "Training Loss: 3.541 | Training Acc: 20.244% (2754/13604)\n",
      "Training Loss: 3.533 | Training Acc: 20.308% (2844/14004)\n",
      "Training Loss: 3.543 | Training Acc: 20.258% (2918/14404)\n",
      "Training Loss: 3.536 | Training Acc: 20.332% (3010/14804)\n",
      "Training Loss: 3.534 | Training Acc: 20.297% (3086/15204)\n",
      "Training Loss: 3.537 | Training Acc: 20.283% (3165/15604)\n",
      "Training Loss: 3.530 | Training Acc: 20.289% (3247/16004)\n",
      "Training Loss: 3.534 | Training Acc: 20.282% (3327/16404)\n",
      "Training Loss: 3.531 | Training Acc: 20.293% (3410/16804)\n",
      "Training Loss: 3.530 | Training Acc: 20.251% (3484/17204)\n",
      "Training Loss: 3.533 | Training Acc: 20.268% (3568/17604)\n",
      "Training Loss: 3.539 | Training Acc: 20.229% (3642/18004)\n",
      "Training Loss: 3.548 | Training Acc: 20.164% (3711/18404)\n",
      "Training Loss: 3.551 | Training Acc: 20.214% (3801/18804)\n",
      "Training Loss: 3.550 | Training Acc: 20.287% (3896/19204)\n",
      "Training Loss: 3.551 | Training Acc: 20.276% (3975/19604)\n",
      "Training Loss: 3.550 | Training Acc: 20.271% (4055/20004)\n",
      "Training Loss: 3.544 | Training Acc: 20.320% (4146/20404)\n",
      "Training Loss: 3.536 | Training Acc: 20.352% (4234/20804)\n",
      "Training Loss: 3.538 | Training Acc: 20.383% (4322/21204)\n",
      "Training Loss: 3.539 | Training Acc: 20.371% (4401/21604)\n",
      "Training Loss: 3.545 | Training Acc: 20.278% (4462/22004)\n",
      "Training Loss: 3.547 | Training Acc: 20.295% (4547/22404)\n",
      "Training Loss: 3.550 | Training Acc: 20.225% (4612/22804)\n",
      "Training Loss: 3.547 | Training Acc: 20.272% (4704/23204)\n",
      "Training Loss: 3.550 | Training Acc: 20.264% (4783/23604)\n",
      "Training Loss: 3.546 | Training Acc: 20.255% (4862/24004)\n",
      "Training Loss: 3.547 | Training Acc: 20.263% (4945/24404)\n",
      "Training Loss: 3.545 | Training Acc: 20.339% (5045/24804)\n",
      "Training Loss: 3.551 | Training Acc: 20.350% (5129/25204)\n",
      "Training Loss: 3.548 | Training Acc: 20.325% (5204/25604)\n",
      "Training Loss: 3.548 | Training Acc: 20.308% (5281/26004)\n",
      "Training Loss: 3.548 | Training Acc: 20.334% (5369/26404)\n",
      "Training Loss: 3.544 | Training Acc: 20.310% (5444/26804)\n",
      "Training Loss: 3.547 | Training Acc: 20.298% (5522/27204)\n",
      "Training Loss: 3.546 | Training Acc: 20.298% (5603/27604)\n",
      "Training Loss: 3.546 | Training Acc: 20.261% (5674/28004)\n",
      "Training Loss: 3.547 | Training Acc: 20.233% (5747/28404)\n",
      "Results after epoch 7\n",
      "Training Loss: 3.544 | Training Acc: 20.259% (5816/28708)\n",
      "Training Loss: 2.058 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 3.830 | Training Acc: 20.297% (82/404)\n",
      "Training Loss: 3.662 | Training Acc: 19.776% (159/804)\n",
      "Training Loss: 3.549 | Training Acc: 19.186% (231/1204)\n",
      "Training Loss: 3.494 | Training Acc: 19.327% (310/1604)\n",
      "Training Loss: 3.430 | Training Acc: 19.960% (400/2004)\n",
      "Training Loss: 3.529 | Training Acc: 19.800% (476/2404)\n",
      "Training Loss: 3.535 | Training Acc: 19.900% (558/2804)\n",
      "Training Loss: 3.546 | Training Acc: 20.006% (641/3204)\n",
      "Training Loss: 3.558 | Training Acc: 20.255% (730/3604)\n",
      "Training Loss: 3.545 | Training Acc: 20.055% (803/4004)\n",
      "Training Loss: 3.532 | Training Acc: 20.141% (887/4404)\n",
      "Training Loss: 3.512 | Training Acc: 20.400% (980/4804)\n",
      "Training Loss: 3.498 | Training Acc: 20.465% (1065/5204)\n",
      "Training Loss: 3.479 | Training Acc: 20.628% (1156/5604)\n",
      "Training Loss: 3.462 | Training Acc: 20.736% (1245/6004)\n",
      "Training Loss: 3.463 | Training Acc: 20.924% (1340/6404)\n",
      "Training Loss: 3.487 | Training Acc: 20.899% (1422/6804)\n",
      "Training Loss: 3.468 | Training Acc: 21.072% (1518/7204)\n",
      "Training Loss: 3.480 | Training Acc: 20.976% (1595/7604)\n",
      "Training Loss: 3.494 | Training Acc: 20.815% (1666/8004)\n",
      "Training Loss: 3.505 | Training Acc: 20.562% (1728/8404)\n",
      "Training Loss: 3.513 | Training Acc: 20.491% (1804/8804)\n",
      "Training Loss: 3.496 | Training Acc: 20.513% (1888/9204)\n",
      "Training Loss: 3.497 | Training Acc: 20.439% (1963/9604)\n",
      "Training Loss: 3.505 | Training Acc: 20.422% (2043/10004)\n",
      "Training Loss: 3.507 | Training Acc: 20.329% (2115/10404)\n",
      "Training Loss: 3.502 | Training Acc: 20.409% (2205/10804)\n",
      "Training Loss: 3.497 | Training Acc: 20.403% (2286/11204)\n",
      "Training Loss: 3.502 | Training Acc: 20.355% (2362/11604)\n",
      "Training Loss: 3.500 | Training Acc: 20.393% (2448/12004)\n",
      "Training Loss: 3.498 | Training Acc: 20.381% (2528/12404)\n",
      "Training Loss: 3.500 | Training Acc: 20.415% (2614/12804)\n",
      "Training Loss: 3.498 | Training Acc: 20.426% (2697/13204)\n",
      "Training Loss: 3.492 | Training Acc: 20.656% (2810/13604)\n",
      "Training Loss: 3.489 | Training Acc: 20.644% (2891/14004)\n",
      "Training Loss: 3.483 | Training Acc: 20.723% (2985/14404)\n",
      "Training Loss: 3.479 | Training Acc: 20.792% (3078/14804)\n",
      "Training Loss: 3.478 | Training Acc: 20.837% (3168/15204)\n",
      "Training Loss: 3.475 | Training Acc: 20.854% (3254/15604)\n",
      "Training Loss: 3.466 | Training Acc: 20.951% (3353/16004)\n",
      "Training Loss: 3.471 | Training Acc: 20.970% (3440/16404)\n",
      "Training Loss: 3.473 | Training Acc: 20.941% (3519/16804)\n",
      "Training Loss: 3.477 | Training Acc: 20.885% (3593/17204)\n",
      "Training Loss: 3.480 | Training Acc: 20.853% (3671/17604)\n",
      "Training Loss: 3.473 | Training Acc: 20.879% (3759/18004)\n",
      "Training Loss: 3.464 | Training Acc: 20.925% (3851/18404)\n",
      "Training Loss: 3.466 | Training Acc: 20.905% (3931/18804)\n",
      "Training Loss: 3.467 | Training Acc: 20.876% (4009/19204)\n",
      "Training Loss: 3.472 | Training Acc: 20.868% (4091/19604)\n",
      "Training Loss: 3.479 | Training Acc: 20.921% (4185/20004)\n",
      "Training Loss: 3.474 | Training Acc: 20.986% (4282/20404)\n",
      "Training Loss: 3.478 | Training Acc: 21.020% (4373/20804)\n",
      "Training Loss: 3.488 | Training Acc: 21.034% (4460/21204)\n",
      "Training Loss: 3.489 | Training Acc: 21.042% (4546/21604)\n",
      "Training Loss: 3.492 | Training Acc: 20.992% (4619/22004)\n",
      "Training Loss: 3.500 | Training Acc: 20.929% (4689/22404)\n",
      "Training Loss: 3.498 | Training Acc: 20.904% (4767/22804)\n",
      "Training Loss: 3.497 | Training Acc: 20.880% (4845/23204)\n",
      "Training Loss: 3.492 | Training Acc: 20.924% (4939/23604)\n",
      "Training Loss: 3.494 | Training Acc: 20.880% (5012/24004)\n",
      "Training Loss: 3.496 | Training Acc: 20.870% (5093/24404)\n",
      "Training Loss: 3.496 | Training Acc: 20.880% (5179/24804)\n",
      "Training Loss: 3.494 | Training Acc: 20.897% (5267/25204)\n",
      "Training Loss: 3.497 | Training Acc: 20.840% (5336/25604)\n",
      "Training Loss: 3.494 | Training Acc: 20.854% (5423/26004)\n",
      "Training Loss: 3.496 | Training Acc: 20.838% (5502/26404)\n",
      "Training Loss: 3.496 | Training Acc: 20.877% (5596/26804)\n",
      "Training Loss: 3.497 | Training Acc: 20.868% (5677/27204)\n",
      "Training Loss: 3.495 | Training Acc: 20.885% (5765/27604)\n",
      "Training Loss: 3.497 | Training Acc: 20.847% (5838/28004)\n",
      "Training Loss: 3.495 | Training Acc: 20.867% (5927/28404)\n",
      "Results after epoch 8\n",
      "Training Loss: 3.494 | Training Acc: 20.869% (5991/28708)\n",
      "Training Loss: 1.813 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 3.232 | Training Acc: 23.762% (96/404)\n",
      "Training Loss: 3.439 | Training Acc: 21.144% (170/804)\n",
      "Training Loss: 3.434 | Training Acc: 19.850% (239/1204)\n",
      "Training Loss: 3.502 | Training Acc: 19.514% (313/1604)\n",
      "Training Loss: 3.495 | Training Acc: 20.559% (412/2004)\n",
      "Training Loss: 3.478 | Training Acc: 20.882% (502/2404)\n",
      "Training Loss: 3.471 | Training Acc: 21.362% (599/2804)\n",
      "Training Loss: 3.482 | Training Acc: 21.536% (690/3204)\n",
      "Training Loss: 3.504 | Training Acc: 21.226% (765/3604)\n",
      "Training Loss: 3.517 | Training Acc: 21.254% (851/4004)\n",
      "Training Loss: 3.505 | Training Acc: 21.639% (953/4404)\n",
      "Training Loss: 3.500 | Training Acc: 21.628% (1039/4804)\n",
      "Training Loss: 3.484 | Training Acc: 21.503% (1119/5204)\n",
      "Training Loss: 3.513 | Training Acc: 21.413% (1200/5604)\n",
      "Training Loss: 3.514 | Training Acc: 21.302% (1279/6004)\n",
      "Training Loss: 3.508 | Training Acc: 21.190% (1357/6404)\n",
      "Training Loss: 3.508 | Training Acc: 21.223% (1444/6804)\n",
      "Training Loss: 3.494 | Training Acc: 21.363% (1539/7204)\n",
      "Training Loss: 3.482 | Training Acc: 21.436% (1630/7604)\n",
      "Training Loss: 3.484 | Training Acc: 21.414% (1714/8004)\n",
      "Training Loss: 3.489 | Training Acc: 21.478% (1805/8404)\n",
      "Training Loss: 3.492 | Training Acc: 21.456% (1889/8804)\n",
      "Training Loss: 3.505 | Training Acc: 21.404% (1970/9204)\n",
      "Training Loss: 3.530 | Training Acc: 21.356% (2051/9604)\n",
      "Training Loss: 3.531 | Training Acc: 21.311% (2132/10004)\n",
      "Training Loss: 3.520 | Training Acc: 21.319% (2218/10404)\n",
      "Training Loss: 3.520 | Training Acc: 21.344% (2306/10804)\n",
      "Training Loss: 3.512 | Training Acc: 21.305% (2387/11204)\n",
      "Training Loss: 3.516 | Training Acc: 21.398% (2483/11604)\n",
      "Training Loss: 3.513 | Training Acc: 21.401% (2569/12004)\n",
      "Training Loss: 3.518 | Training Acc: 21.316% (2644/12404)\n",
      "Training Loss: 3.517 | Training Acc: 21.243% (2720/12804)\n",
      "Training Loss: 3.509 | Training Acc: 21.319% (2815/13204)\n",
      "Training Loss: 3.504 | Training Acc: 21.317% (2900/13604)\n",
      "Training Loss: 3.508 | Training Acc: 21.230% (2973/14004)\n",
      "Training Loss: 3.507 | Training Acc: 21.244% (3060/14404)\n",
      "Training Loss: 3.512 | Training Acc: 21.143% (3130/14804)\n",
      "Training Loss: 3.508 | Training Acc: 21.244% (3230/15204)\n",
      "Training Loss: 3.502 | Training Acc: 21.245% (3315/15604)\n",
      "Training Loss: 3.505 | Training Acc: 21.207% (3394/16004)\n",
      "Training Loss: 3.507 | Training Acc: 21.153% (3470/16404)\n",
      "Training Loss: 3.508 | Training Acc: 21.120% (3549/16804)\n",
      "Training Loss: 3.513 | Training Acc: 21.071% (3625/17204)\n",
      "Training Loss: 3.519 | Training Acc: 21.046% (3705/17604)\n",
      "Training Loss: 3.519 | Training Acc: 21.051% (3790/18004)\n",
      "Training Loss: 3.518 | Training Acc: 21.017% (3868/18404)\n",
      "Training Loss: 3.514 | Training Acc: 20.964% (3942/18804)\n",
      "Training Loss: 3.513 | Training Acc: 20.918% (4017/19204)\n",
      "Training Loss: 3.510 | Training Acc: 20.838% (4085/19604)\n",
      "Training Loss: 3.512 | Training Acc: 20.811% (4163/20004)\n",
      "Training Loss: 3.511 | Training Acc: 20.795% (4243/20404)\n",
      "Training Loss: 3.502 | Training Acc: 20.914% (4351/20804)\n",
      "Training Loss: 3.501 | Training Acc: 20.972% (4447/21204)\n",
      "Training Loss: 3.496 | Training Acc: 20.927% (4521/21604)\n",
      "Training Loss: 3.493 | Training Acc: 20.942% (4608/22004)\n",
      "Training Loss: 3.494 | Training Acc: 20.898% (4682/22404)\n",
      "Training Loss: 3.496 | Training Acc: 20.922% (4771/22804)\n",
      "Training Loss: 3.502 | Training Acc: 20.858% (4840/23204)\n",
      "Training Loss: 3.501 | Training Acc: 20.835% (4918/23604)\n",
      "Training Loss: 3.500 | Training Acc: 20.901% (5017/24004)\n",
      "Training Loss: 3.502 | Training Acc: 20.906% (5102/24404)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m---> 19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\soca274177\\AppData\\Local\\anaconda3\\envs\\facialrecognition\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\soca274177\\AppData\\Local\\anaconda3\\envs\\facialrecognition\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "        if inputs.shape[0] != 4:\n",
    "            continue\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # print(inputs.shape)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        total += len(outputs)\n",
    "        correct += torch.sum(predicted == torch.argmax(targets, dim=1))\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Training Loss: %.3f | Training Acc: %.3f%% (%d/%d)'\n",
    "                 % (train_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "\n",
    "    print('Results after epoch %d' % (epoch + 1))\n",
    "\n",
    "    print('Training Loss: %.3f | Training Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After reference 2\n",
    "\n",
    "\\[2] - Mollahosseini, Ali, et al. „Going Deeper in Facial Expression Recognition using Deep Neural Networks”. 2016 IEEE Winter Conference on Applications of Computer Vision (WACV), 2016, pp. 1–10. arXiv.org, https://doi.org/10.1109/WACV.2016.7477450."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNetwork(nn.Module):\n",
    "    def __init__(self , in_channels = 1, num_classes = 7, reps = 3):\n",
    "        super(InceptionNetwork,self).__init__()\n",
    "\n",
    "        self.conv1 =  ConvolutionBlock(in_channels,64,7,2,1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)\n",
    "\n",
    "        self.conv2 =  ConvolutionBlock(64,192,3,1,1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)\n",
    "        \n",
    "        # in_channels , out_1x1 , red_3x3 , out_3x3 , red_5x5 , out_5x5 , out_1x1_pooling\n",
    "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        # self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)\n",
    "        self.inception4a = InceptionBlock(256, 192, 96, 208, 16, 48, 64)\n",
    "\n",
    "        self.avgPool = nn.AvgPool2d(kernel_size=3,stride=2,padding=0)\n",
    "        self.fc1 = nn.Linear( 480 , 4096)\n",
    "        self.fc2 = nn.Linear( 4096 , 1024)\n",
    "        self.fc3 = nn.Linear( 1024 , 7)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "\n",
    "        x = self.avgPool(x)\n",
    "\n",
    "        flattened = x.view(4, -1)\n",
    "        x = self.fc1(flattened)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testInceptionBlock():\n",
    "    x = torch.randn((4,1,48,48))\n",
    "    model = InceptionNetwork()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionNetwork(\n",
       "  (conv1): ConvolutionBlock(\n",
       "    (conv2d): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): ConvolutionBlock(\n",
       "    (conv2d): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batchnorm2d): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (inception3a): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (inception4a): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgPool): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=480, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testInceptionBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionNetwork()\n",
    "model = model.to(device=device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "\n",
    "        \n",
    "        if inputs.shape[0] != 4:\n",
    "            continue\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += len(outputs)\n",
    "        correct += torch.sum(predicted == torch.argmax(targets, dim=1))\n",
    "\n",
    "    print('  >>> Validation Loss: %.3f | Validation Acc: %.3f%% (%d/%d)'\n",
    "        % (valid_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "    \n",
    "    return valid_loss / (batch_idx + 1), 100. * float(correct) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "\n",
    "scheduler = PolynomialLR(optimizer=optimizer, total_iters=10, power=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training starting...\n",
      "Training Loss: 1.923 | Training Acc: 25.000% (1/4)\n",
      "Training Loss: 1.810 | Training Acc: 26.374% (2111/8004)\n",
      "Training Loss: 1.733 | Training Acc: 29.786% (4767/16004)\n",
      "Training Loss: 1.679 | Training Acc: 32.365% (7769/24004)\n",
      ">>> Results after epoch 1\n",
      "  >>> Training Loss: 1.650 | Training Acc: 33.593% (9644/28708)\n",
      "  >>> Validation Loss: 1.474 | Validation Acc: 40.803% (1464/3588)\n",
      "Training Loss: 2.285 | Training Acc: 0.000% (0/4)\n",
      "Training Loss: 1.455 | Training Acc: 42.591% (3409/8004)\n",
      "Training Loss: 1.438 | Training Acc: 43.127% (6902/16004)\n",
      "Training Loss: 1.428 | Training Acc: 43.651% (10478/24004)\n",
      ">>> Results after epoch 2\n",
      "  >>> Training Loss: 1.418 | Training Acc: 44.151% (12675/28708)\n",
      "  >>> Validation Loss: 1.334 | Validation Acc: 50.056% (1796/3588)\n",
      "Training Loss: 0.760 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 1.311 | Training Acc: 48.226% (3860/8004)\n",
      "Training Loss: 1.300 | Training Acc: 49.175% (7870/16004)\n",
      "Training Loss: 1.299 | Training Acc: 49.663% (11921/24004)\n",
      ">>> Results after epoch 3\n",
      "  >>> Training Loss: 1.292 | Training Acc: 49.930% (14334/28708)\n",
      "  >>> Validation Loss: 1.297 | Validation Acc: 49.777% (1786/3588)\n",
      "Training Loss: 1.390 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 1.210 | Training Acc: 53.298% (4266/8004)\n",
      "Training Loss: 1.213 | Training Acc: 53.424% (8550/16004)\n",
      "Training Loss: 1.209 | Training Acc: 53.574% (12860/24004)\n",
      ">>> Results after epoch 4\n",
      "  >>> Training Loss: 1.206 | Training Acc: 53.779% (15439/28708)\n",
      "  >>> Validation Loss: 1.237 | Validation Acc: 52.954% (1900/3588)\n",
      "Training Loss: 0.749 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 1.119 | Training Acc: 57.821% (4628/8004)\n",
      "Training Loss: 1.130 | Training Acc: 57.336% (9176/16004)\n",
      "Training Loss: 1.129 | Training Acc: 57.132% (13714/24004)\n",
      ">>> Results after epoch 5\n",
      "  >>> Training Loss: 1.125 | Training Acc: 57.308% (16452/28708)\n",
      "  >>> Validation Loss: 1.153 | Validation Acc: 55.881% (2005/3588)\n",
      "Training Loss: 1.317 | Training Acc: 25.000% (1/4)\n",
      "Training Loss: 1.023 | Training Acc: 61.594% (4930/8004)\n",
      "Training Loss: 1.034 | Training Acc: 61.060% (9772/16004)\n",
      "Training Loss: 1.037 | Training Acc: 61.127% (14673/24004)\n",
      ">>> Results after epoch 6\n",
      "  >>> Training Loss: 1.041 | Training Acc: 60.910% (17486/28708)\n",
      "  >>> Validation Loss: 1.192 | Validation Acc: 57.469% (2062/3588)\n",
      "Training Loss: 0.889 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.954 | Training Acc: 64.080% (5129/8004)\n",
      "Training Loss: 0.952 | Training Acc: 63.934% (10232/16004)\n",
      "Training Loss: 0.958 | Training Acc: 63.760% (15305/24004)\n",
      ">>> Results after epoch 7\n",
      "  >>> Training Loss: 0.959 | Training Acc: 63.773% (18308/28708)\n",
      "  >>> Validation Loss: 1.152 | Validation Acc: 57.887% (2077/3588)\n",
      "Training Loss: 0.630 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.857 | Training Acc: 68.066% (5448/8004)\n",
      "Training Loss: 0.863 | Training Acc: 67.764% (10845/16004)\n",
      "Training Loss: 0.869 | Training Acc: 67.597% (16226/24004)\n",
      ">>> Results after epoch 8\n",
      "  >>> Training Loss: 0.872 | Training Acc: 67.448% (19363/28708)\n",
      "  >>> Validation Loss: 1.194 | Validation Acc: 58.110% (2085/3588)\n",
      "Training Loss: 0.420 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.758 | Training Acc: 71.339% (5710/8004)\n",
      "Training Loss: 0.778 | Training Acc: 70.451% (11275/16004)\n",
      "Training Loss: 0.781 | Training Acc: 70.613% (16950/24004)\n",
      ">>> Results after epoch 9\n",
      "  >>> Training Loss: 0.784 | Training Acc: 70.520% (20245/28708)\n",
      "  >>> Validation Loss: 1.265 | Validation Acc: 57.414% (2060/3588)\n",
      "Training Loss: 0.324 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.658 | Training Acc: 75.587% (6050/8004)\n",
      "Training Loss: 0.667 | Training Acc: 75.431% (12072/16004)\n",
      "Training Loss: 0.668 | Training Acc: 75.471% (18116/24004)\n",
      ">>> Results after epoch 10\n",
      "  >>> Training Loss: 0.669 | Training Acc: 75.467% (21665/28708)\n",
      "  >>> Validation Loss: 1.322 | Validation Acc: 59.365% (2130/3588)\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "print(\">>> Training starting...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "        if inputs.shape[0] != 4:\n",
    "            continue\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # print(inputs.shape)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        total += len(outputs)\n",
    "        correct += torch.sum(predicted == torch.argmax(targets, dim=1))\n",
    "\n",
    "        if batch_idx % 2000 == 0:\n",
    "            print('Training Loss: %.3f | Training Acc: %.3f%% (%d/%d)'\n",
    "                 % (train_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "            train_losses.append(train_loss / (batch_idx + 1))\n",
    "            train_acc.append(100. * float(correct) / total)\n",
    "\n",
    "    print('>>> Results after epoch %d' % (epoch + 1))\n",
    "\n",
    "    print('  >>> Training Loss: %.3f | Training Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "   \n",
    "    val_loss, val_acc = evaluate()\n",
    "    valid_loss.append(val_loss)\n",
    "    valid_acc.append(val_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNetwork(nn.Module):\n",
    "    def __init__(self , in_channels = 1, num_classes = 7, reps = 3):\n",
    "        super(InceptionNetwork,self).__init__()\n",
    "\n",
    "        self.conv1 =  ConvolutionBlock(in_channels,64,7,2,3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "        self.conv2 =  ConvolutionBlock(64,192,3,1,1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        # in_channels , out_1x1 , red_3x3 , out_3x3 , red_5x5 , out_5x5 , out_1x1_pooling\n",
    "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        # self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
    "\n",
    "        self.avgPool = nn.AvgPool2d(kernel_size=3,stride=1,padding=0)\n",
    "        self.fc1 = nn.Linear( 512 , 4096)\n",
    "        self.fc2 = nn.Linear( 4096 , 1024)\n",
    "        self.fc3 = nn.Linear( 1024 , 7)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "\n",
    "        x = self.inception3b(x)\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        \n",
    "        x = self.avgPool(x)\n",
    "\n",
    "        flattened = x.view(4, -1)\n",
    "        x = self.fc1(flattened)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    " \n",
    " \n",
    "def testInceptionBlock():\n",
    "    x = torch.randn((4,1,48,48))\n",
    "    model = InceptionNetwork()\n",
    "    rez = model(x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionNetwork(\n",
       "  (conv1): ConvolutionBlock(\n",
       "    (conv2d): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): ConvolutionBlock(\n",
       "    (conv2d): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (batchnorm2d): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception3a): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception4a): InceptionBlock(\n",
       "    (branch1): ConvolutionBlock(\n",
       "      (conv2d): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm2d): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): ConvolutionBlock(\n",
       "        (conv2d): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgPool): AvgPool2d(kernel_size=3, stride=1, padding=0)\n",
       "  (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testInceptionBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionNetwork()\n",
    "model = model.to(device=device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "\n",
    "scheduler = PolynomialLR(optimizer=optimizer, total_iters=20, power=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training starting...\n",
      "Training Loss: 1.927 | Training Acc: 25.000% (1/4)\n",
      "Training Loss: 1.957 | Training Acc: 21.402% (1713/8004)\n",
      "Training Loss: 1.878 | Training Acc: 23.532% (3766/16004)\n",
      "Training Loss: 1.822 | Training Acc: 25.996% (6240/24004)\n",
      ">>> Results after epoch 1\n",
      "  >>> Training Loss: 1.792 | Training Acc: 27.142% (7792/28708)\n",
      "  >>> Validation Loss: 1.549 | Validation Acc: 37.570% (1348/3588)\n",
      "Training Loss: 1.450 | Training Acc: 25.000% (1/4)\n",
      "Training Loss: 1.564 | Training Acc: 36.994% (2961/8004)\n",
      "Training Loss: 1.538 | Training Acc: 37.853% (6058/16004)\n",
      "Training Loss: 1.511 | Training Acc: 39.210% (9412/24004)\n",
      ">>> Results after epoch 2\n",
      "  >>> Training Loss: 1.494 | Training Acc: 40.100% (11512/28708)\n",
      "  >>> Validation Loss: 1.417 | Validation Acc: 44.816% (1608/3588)\n",
      "Training Loss: 1.450 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 1.391 | Training Acc: 45.877% (3672/8004)\n",
      "Training Loss: 1.366 | Training Acc: 46.851% (7498/16004)\n",
      "Training Loss: 1.346 | Training Acc: 47.492% (11400/24004)\n",
      ">>> Results after epoch 3\n",
      "  >>> Training Loss: 1.340 | Training Acc: 47.802% (13723/28708)\n",
      "  >>> Validation Loss: 1.283 | Validation Acc: 50.808% (1823/3588)\n",
      "Training Loss: 1.566 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 1.269 | Training Acc: 50.812% (4067/8004)\n",
      "Training Loss: 1.262 | Training Acc: 51.425% (8230/16004)\n",
      "Training Loss: 1.254 | Training Acc: 51.958% (12472/24004)\n",
      ">>> Results after epoch 4\n",
      "  >>> Training Loss: 1.248 | Training Acc: 52.250% (15000/28708)\n",
      "  >>> Validation Loss: 1.244 | Validation Acc: 51.338% (1842/3588)\n",
      "Training Loss: 1.262 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 1.175 | Training Acc: 54.960% (4399/8004)\n",
      "Training Loss: 1.178 | Training Acc: 55.161% (8828/16004)\n",
      "Training Loss: 1.174 | Training Acc: 55.470% (13315/24004)\n",
      ">>> Results after epoch 5\n",
      "  >>> Training Loss: 1.167 | Training Acc: 55.629% (15970/28708)\n",
      "  >>> Validation Loss: 1.196 | Validation Acc: 54.404% (1952/3588)\n",
      "Training Loss: 0.314 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 1.070 | Training Acc: 59.270% (4744/8004)\n",
      "Training Loss: 1.083 | Training Acc: 58.610% (9380/16004)\n",
      "Training Loss: 1.087 | Training Acc: 58.757% (14104/24004)\n",
      ">>> Results after epoch 6\n",
      "  >>> Training Loss: 1.085 | Training Acc: 58.799% (16880/28708)\n",
      "  >>> Validation Loss: 1.176 | Validation Acc: 55.992% (2009/3588)\n",
      "Training Loss: 0.626 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 1.015 | Training Acc: 61.982% (4961/8004)\n",
      "Training Loss: 1.010 | Training Acc: 62.247% (9962/16004)\n",
      "Training Loss: 1.012 | Training Acc: 62.181% (14926/24004)\n",
      ">>> Results after epoch 7\n",
      "  >>> Training Loss: 1.012 | Training Acc: 62.021% (17805/28708)\n",
      "  >>> Validation Loss: 1.138 | Validation Acc: 59.281% (2127/3588)\n",
      "Training Loss: 0.575 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.915 | Training Acc: 65.905% (5275/8004)\n",
      "Training Loss: 0.923 | Training Acc: 65.490% (10481/16004)\n",
      "Training Loss: 0.929 | Training Acc: 65.160% (15641/24004)\n",
      ">>> Results after epoch 8\n",
      "  >>> Training Loss: 0.931 | Training Acc: 65.062% (18678/28708)\n",
      "  >>> Validation Loss: 1.195 | Validation Acc: 58.305% (2092/3588)\n",
      "Training Loss: 2.266 | Training Acc: 50.000% (2/4)\n",
      "Training Loss: 0.838 | Training Acc: 68.978% (5521/8004)\n",
      "Training Loss: 0.848 | Training Acc: 68.427% (10951/16004)\n",
      "Training Loss: 0.856 | Training Acc: 68.051% (16335/24004)\n",
      ">>> Results after epoch 9\n",
      "  >>> Training Loss: 0.856 | Training Acc: 68.093% (19548/28708)\n",
      "  >>> Validation Loss: 1.198 | Validation Acc: 56.187% (2016/3588)\n",
      "Training Loss: 0.088 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.744 | Training Acc: 72.751% (5823/8004)\n",
      "Training Loss: 0.761 | Training Acc: 71.963% (11517/16004)\n",
      "Training Loss: 0.767 | Training Acc: 71.526% (17169/24004)\n",
      ">>> Results after epoch 10\n",
      "  >>> Training Loss: 0.772 | Training Acc: 71.433% (20507/28708)\n",
      "  >>> Validation Loss: 1.176 | Validation Acc: 59.169% (2123/3588)\n",
      "Training Loss: 0.082 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.671 | Training Acc: 75.175% (6017/8004)\n",
      "Training Loss: 0.688 | Training Acc: 74.638% (11945/16004)\n",
      "Training Loss: 0.694 | Training Acc: 74.496% (17882/24004)\n",
      ">>> Results after epoch 11\n",
      "  >>> Training Loss: 0.697 | Training Acc: 74.255% (21317/28708)\n",
      "  >>> Validation Loss: 1.233 | Validation Acc: 59.504% (2135/3588)\n",
      "Training Loss: 0.924 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.580 | Training Acc: 78.448% (6279/8004)\n",
      "Training Loss: 0.594 | Training Acc: 77.824% (12455/16004)\n",
      "Training Loss: 0.607 | Training Acc: 77.491% (18601/24004)\n",
      ">>> Results after epoch 12\n",
      "  >>> Training Loss: 0.612 | Training Acc: 77.233% (22172/28708)\n",
      "  >>> Validation Loss: 1.281 | Validation Acc: 60.535% (2172/3588)\n",
      "Training Loss: 0.312 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.507 | Training Acc: 81.322% (6509/8004)\n",
      "Training Loss: 0.522 | Training Acc: 80.886% (12945/16004)\n",
      "Training Loss: 0.533 | Training Acc: 80.378% (19294/24004)\n",
      ">>> Results after epoch 13\n",
      "  >>> Training Loss: 0.534 | Training Acc: 80.330% (23061/28708)\n",
      "  >>> Validation Loss: 1.351 | Validation Acc: 60.340% (2165/3588)\n",
      "Training Loss: 0.657 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.428 | Training Acc: 84.345% (6751/8004)\n",
      "Training Loss: 0.437 | Training Acc: 83.885% (13425/16004)\n",
      "Training Loss: 0.452 | Training Acc: 83.357% (20009/24004)\n",
      ">>> Results after epoch 14\n",
      "  >>> Training Loss: 0.459 | Training Acc: 83.036% (23838/28708)\n",
      "  >>> Validation Loss: 1.476 | Validation Acc: 60.340% (2165/3588)\n",
      "Training Loss: 0.174 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.367 | Training Acc: 86.732% (6942/8004)\n",
      "Training Loss: 0.375 | Training Acc: 86.516% (13846/16004)\n",
      "Training Loss: 0.391 | Training Acc: 85.894% (20618/24004)\n",
      ">>> Results after epoch 15\n",
      "  >>> Training Loss: 0.394 | Training Acc: 85.774% (24624/28708)\n",
      "  >>> Validation Loss: 1.533 | Validation Acc: 60.256% (2162/3588)\n",
      "Training Loss: 0.116 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.303 | Training Acc: 89.230% (7142/8004)\n",
      "Training Loss: 0.322 | Training Acc: 88.397% (14147/16004)\n",
      "Training Loss: 0.324 | Training Acc: 88.231% (21179/24004)\n",
      ">>> Results after epoch 16\n",
      "  >>> Training Loss: 0.331 | Training Acc: 88.042% (25275/28708)\n",
      "  >>> Validation Loss: 1.684 | Validation Acc: 60.702% (2178/3588)\n",
      "Training Loss: 0.893 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.252 | Training Acc: 91.092% (7291/8004)\n",
      "Training Loss: 0.262 | Training Acc: 90.615% (14502/16004)\n",
      "Training Loss: 0.270 | Training Acc: 90.268% (21668/24004)\n",
      ">>> Results after epoch 17\n",
      "  >>> Training Loss: 0.271 | Training Acc: 90.222% (25901/28708)\n",
      "  >>> Validation Loss: 1.808 | Validation Acc: 60.368% (2166/3588)\n",
      "Training Loss: 0.097 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.203 | Training Acc: 93.003% (7444/8004)\n",
      "Training Loss: 0.212 | Training Acc: 92.577% (14816/16004)\n",
      "Training Loss: 0.210 | Training Acc: 92.655% (22241/24004)\n",
      ">>> Results after epoch 18\n",
      "  >>> Training Loss: 0.217 | Training Acc: 92.347% (26511/28708)\n",
      "  >>> Validation Loss: 1.926 | Validation Acc: 59.922% (2150/3588)\n",
      "Training Loss: 0.282 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.144 | Training Acc: 94.928% (7598/8004)\n",
      "Training Loss: 0.156 | Training Acc: 94.501% (15124/16004)\n",
      "Training Loss: 0.163 | Training Acc: 94.243% (22622/24004)\n",
      ">>> Results after epoch 19\n",
      "  >>> Training Loss: 0.165 | Training Acc: 94.113% (27018/28708)\n",
      "  >>> Validation Loss: 2.178 | Validation Acc: 60.953% (2187/3588)\n",
      "Training Loss: 0.009 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.112 | Training Acc: 96.114% (7693/8004)\n",
      "Training Loss: 0.113 | Training Acc: 96.082% (15377/16004)\n",
      "Training Loss: 0.118 | Training Acc: 95.967% (23036/24004)\n",
      ">>> Results after epoch 20\n",
      "  >>> Training Loss: 0.119 | Training Acc: 95.921% (27537/28708)\n",
      "  >>> Validation Loss: 2.244 | Validation Acc: 59.950% (2151/3588)\n",
      "Training Loss: 0.017 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.080 | Training Acc: 97.476% (7802/8004)\n",
      "Training Loss: 0.082 | Training Acc: 97.332% (15577/16004)\n",
      "Training Loss: 0.082 | Training Acc: 97.359% (23370/24004)\n",
      ">>> Results after epoch 21\n",
      "  >>> Training Loss: 0.082 | Training Acc: 97.335% (27943/28708)\n",
      "  >>> Validation Loss: 2.282 | Validation Acc: 59.838% (2147/3588)\n",
      "Training Loss: 0.015 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.079 | Training Acc: 97.401% (7796/8004)\n",
      "Training Loss: 0.078 | Training Acc: 97.532% (15609/16004)\n",
      "Training Loss: 0.078 | Training Acc: 97.525% (23410/24004)\n",
      ">>> Results after epoch 22\n",
      "  >>> Training Loss: 0.078 | Training Acc: 97.513% (27994/28708)\n",
      "  >>> Validation Loss: 2.226 | Validation Acc: 60.089% (2156/3588)\n",
      "Training Loss: 0.731 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.082 | Training Acc: 97.514% (7805/8004)\n",
      "Training Loss: 0.081 | Training Acc: 97.494% (15603/16004)\n",
      "Training Loss: 0.081 | Training Acc: 97.492% (23402/24004)\n",
      ">>> Results after epoch 23\n",
      "  >>> Training Loss: 0.079 | Training Acc: 97.520% (27996/28708)\n",
      "  >>> Validation Loss: 2.269 | Validation Acc: 60.842% (2183/3588)\n",
      "Training Loss: 0.011 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.081 | Training Acc: 97.476% (7802/8004)\n",
      "Training Loss: 0.078 | Training Acc: 97.576% (15616/16004)\n",
      "Training Loss: 0.081 | Training Acc: 97.384% (23376/24004)\n",
      ">>> Results after epoch 24\n",
      "  >>> Training Loss: 0.081 | Training Acc: 97.398% (27961/28708)\n",
      "  >>> Validation Loss: 2.259 | Validation Acc: 60.061% (2155/3588)\n",
      "Training Loss: 0.146 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.069 | Training Acc: 97.951% (7840/8004)\n",
      "Training Loss: 0.075 | Training Acc: 97.626% (15624/16004)\n",
      "Training Loss: 0.076 | Training Acc: 97.584% (23424/24004)\n",
      ">>> Results after epoch 25\n",
      "  >>> Training Loss: 0.078 | Training Acc: 97.520% (27996/28708)\n",
      "  >>> Validation Loss: 2.243 | Validation Acc: 59.950% (2151/3588)\n",
      "Training Loss: 0.039 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.084 | Training Acc: 97.426% (7798/8004)\n",
      "Training Loss: 0.080 | Training Acc: 97.469% (15599/16004)\n",
      "Training Loss: 0.080 | Training Acc: 97.492% (23402/24004)\n",
      ">>> Results after epoch 26\n",
      "  >>> Training Loss: 0.081 | Training Acc: 97.408% (27964/28708)\n",
      "  >>> Validation Loss: 2.227 | Validation Acc: 60.368% (2166/3588)\n",
      "Training Loss: 0.004 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.081 | Training Acc: 97.714% (7821/8004)\n",
      "Training Loss: 0.081 | Training Acc: 97.663% (15630/16004)\n",
      "Training Loss: 0.080 | Training Acc: 97.634% (23436/24004)\n",
      ">>> Results after epoch 27\n",
      "  >>> Training Loss: 0.080 | Training Acc: 97.558% (28007/28708)\n",
      "  >>> Validation Loss: 2.351 | Validation Acc: 60.535% (2172/3588)\n",
      "Training Loss: 0.258 | Training Acc: 75.000% (3/4)\n",
      "Training Loss: 0.077 | Training Acc: 97.576% (7810/8004)\n",
      "Training Loss: 0.079 | Training Acc: 97.513% (15606/16004)\n",
      "Training Loss: 0.080 | Training Acc: 97.463% (23395/24004)\n",
      ">>> Results after epoch 28\n",
      "  >>> Training Loss: 0.080 | Training Acc: 97.436% (27972/28708)\n",
      "  >>> Validation Loss: 2.273 | Validation Acc: 60.201% (2160/3588)\n",
      "Training Loss: 0.002 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.079 | Training Acc: 97.576% (7810/8004)\n",
      "Training Loss: 0.084 | Training Acc: 97.407% (15589/16004)\n",
      "Training Loss: 0.083 | Training Acc: 97.400% (23380/24004)\n",
      ">>> Results after epoch 29\n",
      "  >>> Training Loss: 0.082 | Training Acc: 97.405% (27963/28708)\n",
      "  >>> Validation Loss: 2.235 | Validation Acc: 60.089% (2156/3588)\n",
      "Training Loss: 0.016 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.078 | Training Acc: 97.589% (7811/8004)\n",
      "Training Loss: 0.079 | Training Acc: 97.463% (15598/16004)\n",
      "Training Loss: 0.078 | Training Acc: 97.542% (23414/24004)\n",
      ">>> Results after epoch 30\n",
      "  >>> Training Loss: 0.079 | Training Acc: 97.523% (27997/28708)\n",
      "  >>> Validation Loss: 2.286 | Validation Acc: 60.033% (2154/3588)\n",
      "Training Loss: 0.020 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.084 | Training Acc: 97.226% (7782/8004)\n",
      "Training Loss: 0.082 | Training Acc: 97.357% (15581/16004)\n",
      "Training Loss: 0.083 | Training Acc: 97.392% (23378/24004)\n",
      ">>> Results after epoch 31\n",
      "  >>> Training Loss: 0.083 | Training Acc: 97.387% (27958/28708)\n",
      "  >>> Validation Loss: 2.285 | Validation Acc: 60.591% (2174/3588)\n",
      "Training Loss: 0.128 | Training Acc: 100.000% (4/4)\n",
      "Training Loss: 0.075 | Training Acc: 97.776% (7826/8004)\n",
      "Training Loss: 0.079 | Training Acc: 97.519% (15607/16004)\n",
      "Training Loss: 0.078 | Training Acc: 97.530% (23411/24004)\n",
      ">>> Results after epoch 32\n",
      "  >>> Training Loss: 0.078 | Training Acc: 97.499% (27990/28708)\n",
      "  >>> Validation Loss: 2.282 | Validation Acc: 60.201% (2160/3588)\n",
      "Training Loss: 0.002 | Training Acc: 100.000% (4/4)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 28\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     29\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(outputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "print(\">>> Training starting...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "        if inputs.shape[0] != 4:\n",
    "            continue\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # print(inputs.shape)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        total += len(outputs)\n",
    "        correct += torch.sum(predicted == torch.argmax(targets, dim=1))\n",
    "\n",
    "        if batch_idx % 2000 == 0:\n",
    "            print('Training Loss: %.3f | Training Acc: %.3f%% (%d/%d)'\n",
    "                 % (train_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "            train_losses.append(train_loss / (batch_idx + 1))\n",
    "            train_acc.append(100. * float(correct) / total)\n",
    "\n",
    "    print('>>> Results after epoch %d' % (epoch + 1))\n",
    "\n",
    "    print('  >>> Training Loss: %.3f | Training Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "   \n",
    "    val_loss, val_acc = evaluate()\n",
    "    valid_loss.append(val_loss)\n",
    "    valid_acc.append(val_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "117 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "        \n",
    "        if inputs.shape[0] != 4:\n",
    "            continue\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += len(outputs)\n",
    "        correct += torch.sum(predicted == torch.argmax(targets, dim=1))\n",
    "\n",
    "    print('  >>> Validation Loss: %.3f | Validation Acc: %.3f%% (%d/%d)'\n",
    "        % (test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total))\n",
    "    \n",
    "    return test_loss / (batch_idx + 1), 100. * float(correct) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  >>> Validation Loss: 2.296 | Validation Acc: 60.535% (2172/3588)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.295506303324972, 60.53511705685619)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
