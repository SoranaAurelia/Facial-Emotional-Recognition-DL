{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d64cb47-2ebd-4a8c-8dfa-78bfa958b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "906c729c-f4a5-429f-9aec-c67f5e7103cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data...\n",
      "training size 28709 : test val size 7178\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "class DataSetFactory:\n",
    "\n",
    "    def __init__(self):\n",
    "        images = []\n",
    "        emotions = []\n",
    "        test_images = []\n",
    "        test_emotions = []\n",
    "\n",
    "        with open('data/fer2013.csv', 'r') as csvin:\n",
    "            data = csv.reader(csvin)\n",
    "            next(data)\n",
    "            for row in data:\n",
    "                face = [int(pixel) for pixel in row[1].split()]\n",
    "                face = np.asarray(face).reshape(48, 48)\n",
    "                face = face.astype('uint8')\n",
    "\n",
    "                if row[-1] == 'Training':\n",
    "                    emotions.append(int(row[0]))\n",
    "                    images.append(Image.fromarray(face))\n",
    "                elif row[-1] == \"PrivateTest\":\n",
    "                    test_emotions.append(int(row[0]))\n",
    "                    test_images.append(Image.fromarray(face))\n",
    "                elif row[-1] == \"PublicTest\":\n",
    "                    test_emotions.append(int(row[0]))\n",
    "                    test_images.append(Image.fromarray(face))\n",
    "\n",
    "        print('training size %d : test val size %d' % (\n",
    "            len(images), len(test_images)))\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.training = DataSet(transform=train_transform, images=images, emotions=emotions)\n",
    "        self.test = DataSet(transform=val_transform, images=test_images, emotions=test_emotions)\n",
    "\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, transform=None, images=None, emotions=None):\n",
    "        self.transform = transform\n",
    "        self.images = images\n",
    "        self.emotions = emotions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        emotion = self.emotions[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, emotion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "print('==> Preparing data...')\n",
    "\n",
    "factory = DataSetFactory()\n",
    "\n",
    "trainingloader = DataLoader(factory.training, batch_size=128, shuffle=True, num_workers=2)\n",
    "validationloader = DataLoader(factory.test, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "classes = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "number_of_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fe74bd-2df6-4bee-bf54-c127a7167518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, num_of_convs: int):\n",
    "        super(Subnet, self).__init__()\n",
    "\n",
    "        if not (num_of_convs >= 3 and num_of_convs <=5):\n",
    "            raise Exception(\"Number of convolution layers can't be lower than 3 and higher than 5!\")\n",
    "        \n",
    "        # number of convolution layers\n",
    "        self.num_of_convs = num_of_convs\n",
    "        \n",
    "        # activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # First convolution layer\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, 3) #46x46\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2) # 23x23\n",
    "\n",
    "        # Second convolution layer\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3) #21x21\n",
    "\n",
    "        # Third convolution layer (only applies if number of convolution layers is 5, otherwise the next layer is the third)\n",
    "        \n",
    "        if self.num_of_convs == 5:\n",
    "            self.conv3 = nn.Conv2d(128, 128, 3) #19x19\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2) # 3,4: 10x10, 5: 9x9\n",
    "\n",
    "        # Fourth convolution layer\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3) #3,4: 8x8, 5:7x7\n",
    "\n",
    "        # Fifth convolution layer (applies if number of convolution layers is 4 or 5, otherwise this layer is ignored)\n",
    "\n",
    "        if self.num_of_convs == 4 or self.num_of_convs == 5:\n",
    "            self.conv5 = nn.Conv2d(256, 256, 3) # 3: 8x8 4: 6x6, 5: 5x5\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2) # 3: 4x4, 4: 3x3, 5: 2x2 \n",
    "\n",
    "        feature_map_size = 7 - self.num_of_convs # 7 magic number for getting the feature_map_size without ifs :))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(256 * feature_map_size * feature_map_size, 4096)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First convolution layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Second convolution layer\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Third convolution layer\n",
    "        if self.num_of_convs == 5:\n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Fourth convolution layer\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Fifth convolution layer\n",
    "        if self.num_of_convs == 4 or self.num_of_convs == 5:\n",
    "            x = self.conv5(x)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        #First fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        #x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34320434-95a9-4b89-8d7b-8eae974e0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Defining the three subnets \n",
    "        self.subnet1 = Subnet(num_of_convs=3)\n",
    "        self.subnet2 = Subnet(num_of_convs=4)\n",
    "        self.subnet3 = Subnet(num_of_convs=5)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(4096*3, number_of_classes)\n",
    "\n",
    "        # Activation function for the last layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x0):\n",
    "\n",
    "        x1 = self.subnet1(x0)\n",
    "        x2 = self.subnet2(x0)\n",
    "        x3 = self.subnet3(x0)\n",
    "\n",
    "        # Concatenation\n",
    "        x = torch.cat([x1, x2, x3], dim = 1)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        #x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d17a32f-dbaa-42f9-922e-b7f60580f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "\n",
    "net = CNN()\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "92efcfcb-c43d-477d-9401-b2626d84aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainingloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Training Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss / (batch_idx + 1), 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20744330-5741-4ea0-9c59-15f8f5a7f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(validationloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Validation Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss / (batch_idx + 1), 100.*correct/total, correct, total))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41689628-a71b-4164-80a5-d41577191b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting training\n",
      "\n",
      "Epoch: 0\n",
      "Training Loss: 1.819 | Acc: 24.922% (7155/28709)\n",
      "Validation Loss: 1.807 | Acc: 24.714% (1774/7178)\n",
      "\n",
      "Epoch: 1\n",
      "Training Loss: 1.795 | Acc: 25.337% (7274/28709)\n",
      "Validation Loss: 1.773 | Acc: 25.815% (1853/7178)\n",
      "\n",
      "Epoch: 2\n",
      "Training Loss: 1.737 | Acc: 28.942% (8309/28709)\n",
      "Validation Loss: 1.686 | Acc: 33.004% (2369/7178)\n",
      "\n",
      "Epoch: 3\n",
      "Training Loss: 1.642 | Acc: 35.923% (10313/28709)\n",
      "Validation Loss: 1.585 | Acc: 39.259% (2818/7178)\n",
      "\n",
      "Epoch: 4\n",
      "Training Loss: 1.561 | Acc: 39.657% (11385/28709)\n",
      "Validation Loss: 1.521 | Acc: 41.683% (2992/7178)\n",
      "\n",
      "Epoch: 5\n",
      "Training Loss: 1.504 | Acc: 41.858% (12017/28709)\n",
      "Validation Loss: 1.476 | Acc: 43.327% (3110/7178)\n",
      "\n",
      "Epoch: 6\n",
      "Training Loss: 1.454 | Acc: 44.063% (12650/28709)\n",
      "Validation Loss: 1.489 | Acc: 42.937% (3082/7178)\n",
      "\n",
      "Epoch: 7\n",
      "Training Loss: 1.408 | Acc: 46.013% (13210/28709)\n",
      "Validation Loss: 1.389 | Acc: 47.005% (3374/7178)\n",
      "\n",
      "Epoch: 8\n",
      "Training Loss: 1.354 | Acc: 48.267% (13857/28709)\n",
      "Validation Loss: 1.348 | Acc: 48.649% (3492/7178)\n",
      "\n",
      "Epoch: 9\n",
      "Training Loss: 1.309 | Acc: 50.329% (14449/28709)\n",
      "Validation Loss: 1.309 | Acc: 49.206% (3532/7178)\n",
      "\n",
      "Epoch: 10\n",
      "Training Loss: 1.260 | Acc: 52.151% (14972/28709)\n",
      "Validation Loss: 1.272 | Acc: 51.212% (3676/7178)\n",
      "\n",
      "Epoch: 11\n",
      "Training Loss: 1.215 | Acc: 54.046% (15516/28709)\n",
      "Validation Loss: 1.251 | Acc: 52.243% (3750/7178)\n",
      "\n",
      "Epoch: 12\n",
      "Training Loss: 1.167 | Acc: 55.881% (16043/28709)\n",
      "Validation Loss: 1.207 | Acc: 53.803% (3862/7178)\n",
      "\n",
      "Epoch: 13\n",
      "Training Loss: 1.132 | Acc: 57.275% (16443/28709)\n",
      "Validation Loss: 1.263 | Acc: 51.003% (3661/7178)\n",
      "\n",
      "Epoch: 14\n",
      "Training Loss: 1.091 | Acc: 58.999% (16938/28709)\n",
      "Validation Loss: 1.190 | Acc: 54.820% (3935/7178)\n",
      "\n",
      "Epoch: 15\n",
      "Training Loss: 1.038 | Acc: 61.214% (17574/28709)\n",
      "Validation Loss: 1.168 | Acc: 55.865% (4010/7178)\n",
      "\n",
      "Epoch: 16\n",
      "Training Loss: 1.004 | Acc: 62.562% (17961/28709)\n",
      "Validation Loss: 1.169 | Acc: 56.548% (4059/7178)\n",
      "\n",
      "Epoch: 17\n",
      "Training Loss: 0.947 | Acc: 64.823% (18610/28709)\n",
      "Validation Loss: 1.203 | Acc: 55.475% (3982/7178)\n",
      "\n",
      "Epoch: 18\n",
      "Training Loss: 0.899 | Acc: 67.021% (19241/28709)\n",
      "Validation Loss: 1.147 | Acc: 58.275% (4183/7178)\n",
      "\n",
      "Epoch: 19\n",
      "Training Loss: 0.847 | Acc: 68.627% (19702/28709)\n",
      "Validation Loss: 1.161 | Acc: 58.220% (4179/7178)\n",
      "\n",
      "Epoch: 20\n",
      "Training Loss: 0.792 | Acc: 70.811% (20329/28709)\n",
      "Validation Loss: 1.190 | Acc: 57.983% (4162/7178)\n",
      "\n",
      "Epoch: 21\n",
      "Training Loss: 0.727 | Acc: 73.604% (21131/28709)\n",
      "Validation Loss: 1.199 | Acc: 58.972% (4233/7178)\n",
      "\n",
      "Epoch: 22\n",
      "Training Loss: 0.669 | Acc: 76.014% (21823/28709)\n",
      "Validation Loss: 1.265 | Acc: 57.439% (4123/7178)\n",
      "\n",
      "Epoch: 23\n",
      "Training Loss: 0.602 | Acc: 78.731% (22603/28709)\n",
      "Validation Loss: 1.353 | Acc: 57.049% (4095/7178)\n",
      "\n",
      "Epoch: 24\n",
      "Training Loss: 0.541 | Acc: 80.828% (23205/28709)\n",
      "Validation Loss: 1.426 | Acc: 54.820% (3935/7178)\n",
      "\n",
      "Epoch: 25\n",
      "Training Loss: 0.475 | Acc: 83.503% (23973/28709)\n",
      "Validation Loss: 1.354 | Acc: 58.624% (4208/7178)\n",
      "\n",
      "Epoch: 26\n",
      "Training Loss: 0.424 | Acc: 85.524% (24553/28709)\n",
      "Validation Loss: 1.436 | Acc: 58.052% (4167/7178)\n",
      "\n",
      "Epoch: 27\n",
      "Training Loss: 0.367 | Acc: 87.718% (25183/28709)\n",
      "Validation Loss: 1.525 | Acc: 58.958% (4232/7178)\n",
      "\n",
      "Epoch: 28\n",
      "Training Loss: 0.312 | Acc: 89.665% (25742/28709)\n",
      "Validation Loss: 1.619 | Acc: 58.094% (4170/7178)\n",
      "\n",
      "Epoch: 29\n",
      "Training Loss: 0.281 | Acc: 90.877% (26090/28709)\n",
      "Validation Loss: 1.617 | Acc: 57.913% (4157/7178)\n",
      "\n",
      "Epoch: 30\n",
      "Training Loss: 0.241 | Acc: 92.292% (26496/28709)\n",
      "Validation Loss: 1.765 | Acc: 58.944% (4231/7178)\n",
      "\n",
      "Epoch: 31\n",
      "Training Loss: 0.214 | Acc: 93.270% (26777/28709)\n",
      "Validation Loss: 1.825 | Acc: 57.328% (4115/7178)\n",
      "\n",
      "Epoch: 32\n",
      "Training Loss: 0.182 | Acc: 94.382% (27096/28709)\n",
      "Validation Loss: 1.846 | Acc: 57.871% (4154/7178)\n",
      "\n",
      "Epoch: 33\n",
      "Training Loss: 0.162 | Acc: 95.172% (27323/28709)\n",
      "Validation Loss: 1.854 | Acc: 59.459% (4268/7178)\n",
      "\n",
      "Epoch: 34\n",
      "Training Loss: 0.139 | Acc: 95.973% (27553/28709)\n",
      "Validation Loss: 1.942 | Acc: 59.181% (4248/7178)\n",
      "\n",
      "Epoch: 35\n",
      "Training Loss: 0.131 | Acc: 96.276% (27640/28709)\n",
      "Validation Loss: 1.899 | Acc: 59.111% (4243/7178)\n",
      "\n",
      "Epoch: 36\n",
      "Training Loss: 0.108 | Acc: 97.123% (27883/28709)\n",
      "Validation Loss: 2.024 | Acc: 58.819% (4222/7178)\n",
      "\n",
      "Epoch: 37\n",
      "Training Loss: 0.110 | Acc: 97.182% (27900/28709)\n",
      "Validation Loss: 1.939 | Acc: 59.195% (4249/7178)\n",
      "\n",
      "Epoch: 38\n",
      "Training Loss: 0.103 | Acc: 97.530% (28000/28709)\n",
      "Validation Loss: 1.981 | Acc: 59.432% (4266/7178)\n",
      "\n",
      "Epoch: 39\n",
      "Training Loss: 0.090 | Acc: 97.760% (28066/28709)\n",
      "Validation Loss: 2.030 | Acc: 58.624% (4208/7178)\n",
      "\n",
      "Epoch: 40\n",
      "Training Loss: 0.072 | Acc: 98.401% (28250/28709)\n",
      "Validation Loss: 2.112 | Acc: 59.376% (4262/7178)\n",
      "\n",
      "Epoch: 41\n",
      "Training Loss: 0.071 | Acc: 98.422% (28256/28709)\n",
      "Validation Loss: 2.093 | Acc: 59.696% (4285/7178)\n",
      "\n",
      "Epoch: 42\n",
      "Training Loss: 0.066 | Acc: 98.774% (28357/28709)\n",
      "Validation Loss: 2.026 | Acc: 59.710% (4286/7178)\n",
      "\n",
      "Epoch: 43\n",
      "Training Loss: 0.056 | Acc: 98.972% (28414/28709)\n",
      "Validation Loss: 2.041 | Acc: 58.930% (4230/7178)\n",
      "\n",
      "Epoch: 44\n",
      "Training Loss: 0.051 | Acc: 99.087% (28447/28709)\n",
      "Validation Loss: 2.123 | Acc: 59.571% (4276/7178)\n",
      "\n",
      "Epoch: 45\n",
      "Training Loss: 0.047 | Acc: 99.171% (28471/28709)\n",
      "Validation Loss: 2.021 | Acc: 60.671% (4355/7178)\n",
      "\n",
      "Epoch: 46\n",
      "Training Loss: 0.044 | Acc: 99.338% (28519/28709)\n",
      "Validation Loss: 2.036 | Acc: 60.880% (4370/7178)\n",
      "\n",
      "Epoch: 47\n",
      "Training Loss: 0.038 | Acc: 99.377% (28530/28709)\n",
      "Validation Loss: 1.970 | Acc: 60.476% (4341/7178)\n",
      "\n",
      "Epoch: 48\n",
      "Training Loss: 0.038 | Acc: 99.453% (28552/28709)\n",
      "Validation Loss: 1.905 | Acc: 60.170% (4319/7178)\n",
      "\n",
      "Epoch: 49\n",
      "Training Loss: 0.036 | Acc: 99.422% (28543/28709)\n",
      "Validation Loss: 1.985 | Acc: 60.170% (4319/7178)\n",
      "\n",
      "Epoch: 50\n",
      "Training Loss: 0.032 | Acc: 99.512% (28569/28709)\n",
      "Validation Loss: 1.976 | Acc: 60.351% (4332/7178)\n",
      "\n",
      "Epoch: 51\n",
      "Training Loss: 0.034 | Acc: 99.481% (28560/28709)\n",
      "Validation Loss: 1.940 | Acc: 60.616% (4351/7178)\n",
      "\n",
      "Epoch: 52\n",
      "Training Loss: 0.032 | Acc: 99.533% (28575/28709)\n",
      "Validation Loss: 1.894 | Acc: 60.644% (4353/7178)\n",
      "\n",
      "Epoch: 53\n",
      "Training Loss: 0.027 | Acc: 99.603% (28595/28709)\n",
      "Validation Loss: 1.880 | Acc: 60.853% (4368/7178)\n",
      "\n",
      "Epoch: 54\n",
      "Training Loss: 0.028 | Acc: 99.558% (28582/28709)\n",
      "Validation Loss: 1.853 | Acc: 61.006% (4379/7178)\n",
      "\n",
      "Epoch: 55\n",
      "Training Loss: 0.029 | Acc: 99.544% (28578/28709)\n",
      "Validation Loss: 1.913 | Acc: 60.741% (4360/7178)\n",
      "\n",
      "Epoch: 56\n",
      "Training Loss: 0.029 | Acc: 99.537% (28576/28709)\n",
      "Validation Loss: 1.862 | Acc: 60.644% (4353/7178)\n",
      "\n",
      "Epoch: 57\n",
      "Training Loss: 0.028 | Acc: 99.606% (28596/28709)\n",
      "Validation Loss: 1.848 | Acc: 60.421% (4337/7178)\n",
      "\n",
      "Epoch: 58\n",
      "Training Loss: 0.026 | Acc: 99.606% (28596/28709)\n",
      "Validation Loss: 1.858 | Acc: 60.867% (4369/7178)\n",
      "\n",
      "Epoch: 59\n",
      "Training Loss: 0.027 | Acc: 99.603% (28595/28709)\n",
      "Validation Loss: 1.922 | Acc: 60.699% (4357/7178)\n",
      "\n",
      "Epoch: 60\n",
      "Training Loss: 0.029 | Acc: 99.589% (28591/28709)\n",
      "Validation Loss: 1.880 | Acc: 59.905% (4300/7178)\n",
      "\n",
      "Epoch: 61\n",
      "Training Loss: 0.029 | Acc: 99.579% (28588/28709)\n",
      "Validation Loss: 1.840 | Acc: 60.713% (4358/7178)\n",
      "\n",
      "Epoch: 62\n",
      "Training Loss: 0.027 | Acc: 99.610% (28597/28709)\n",
      "Validation Loss: 1.827 | Acc: 61.006% (4379/7178)\n",
      "\n",
      "Epoch: 63\n",
      "Training Loss: 0.024 | Acc: 99.645% (28607/28709)\n",
      "Validation Loss: 1.808 | Acc: 60.741% (4360/7178)\n",
      "\n",
      "Epoch: 64\n",
      "Training Loss: 0.026 | Acc: 99.613% (28598/28709)\n",
      "Validation Loss: 1.884 | Acc: 60.309% (4329/7178)\n",
      "\n",
      "Epoch: 65\n",
      "Training Loss: 0.025 | Acc: 99.631% (28603/28709)\n",
      "Validation Loss: 1.796 | Acc: 60.936% (4374/7178)\n",
      "\n",
      "Epoch: 66\n",
      "Training Loss: 0.027 | Acc: 99.613% (28598/28709)\n",
      "Validation Loss: 1.852 | Acc: 60.017% (4308/7178)\n",
      "\n",
      "Epoch: 67\n",
      "Training Loss: 0.026 | Acc: 99.620% (28600/28709)\n",
      "Validation Loss: 1.880 | Acc: 60.254% (4325/7178)\n",
      "\n",
      "Epoch: 68\n",
      "Training Loss: 0.024 | Acc: 99.638% (28605/28709)\n",
      "Validation Loss: 1.855 | Acc: 60.685% (4356/7178)\n",
      "\n",
      "Epoch: 69\n",
      "Training Loss: 0.028 | Acc: 99.592% (28592/28709)\n",
      "Validation Loss: 1.825 | Acc: 61.103% (4386/7178)\n",
      "\n",
      "Epoch: 70\n",
      "Training Loss: 0.025 | Acc: 99.610% (28597/28709)\n",
      "Validation Loss: 1.817 | Acc: 60.727% (4359/7178)\n",
      "\n",
      "Epoch: 71\n",
      "Training Loss: 0.021 | Acc: 99.673% (28615/28709)\n",
      "Validation Loss: 1.833 | Acc: 60.950% (4375/7178)\n",
      "\n",
      "Epoch: 72\n",
      "Training Loss: 0.025 | Acc: 99.620% (28600/28709)\n",
      "Validation Loss: 1.792 | Acc: 61.243% (4396/7178)\n",
      "\n",
      "Epoch: 73\n",
      "Training Loss: 0.024 | Acc: 99.648% (28608/28709)\n",
      "Validation Loss: 1.801 | Acc: 60.783% (4363/7178)\n",
      "\n",
      "Epoch: 74\n",
      "Training Loss: 0.023 | Acc: 99.641% (28606/28709)\n",
      "Validation Loss: 1.908 | Acc: 60.894% (4371/7178)\n",
      "\n",
      "Epoch: 75\n",
      "Training Loss: 0.024 | Acc: 99.659% (28611/28709)\n",
      "Validation Loss: 1.811 | Acc: 60.908% (4372/7178)\n",
      "\n",
      "Epoch: 76\n",
      "Training Loss: 0.030 | Acc: 99.592% (28592/28709)\n",
      "Validation Loss: 1.787 | Acc: 60.783% (4363/7178)\n",
      "\n",
      "Epoch: 77\n",
      "Training Loss: 0.025 | Acc: 99.627% (28602/28709)\n",
      "Validation Loss: 1.834 | Acc: 60.908% (4372/7178)\n",
      "\n",
      "Epoch: 78\n",
      "Training Loss: 0.028 | Acc: 99.606% (28596/28709)\n",
      "Validation Loss: 1.803 | Acc: 60.421% (4337/7178)\n",
      "\n",
      "Epoch: 79\n",
      "Training Loss: 0.027 | Acc: 99.568% (28585/28709)\n",
      "Validation Loss: 1.842 | Acc: 60.658% (4354/7178)\n",
      "\n",
      "Epoch: 80\n",
      "Training Loss: 0.028 | Acc: 99.613% (28598/28709)\n",
      "Validation Loss: 1.838 | Acc: 61.076% (4384/7178)\n",
      "\n",
      "Epoch: 81\n",
      "Training Loss: 0.030 | Acc: 99.547% (28579/28709)\n",
      "Validation Loss: 1.826 | Acc: 60.240% (4324/7178)\n",
      "\n",
      "Epoch: 82\n",
      "Training Loss: 0.032 | Acc: 99.502% (28566/28709)\n",
      "Validation Loss: 1.848 | Acc: 60.407% (4336/7178)\n",
      "\n",
      "Epoch: 83\n",
      "Training Loss: 0.031 | Acc: 99.530% (28574/28709)\n",
      "Validation Loss: 1.852 | Acc: 61.076% (4384/7178)\n",
      "\n",
      "Epoch: 84\n",
      "Training Loss: 0.036 | Acc: 99.366% (28527/28709)\n",
      "Validation Loss: 1.858 | Acc: 59.766% (4290/7178)\n",
      "\n",
      "Epoch: 85\n",
      "Training Loss: 0.038 | Acc: 99.418% (28542/28709)\n",
      "Validation Loss: 1.900 | Acc: 60.685% (4356/7178)\n",
      "\n",
      "Epoch: 86\n",
      "Training Loss: 0.035 | Acc: 99.401% (28537/28709)\n",
      "Validation Loss: 1.997 | Acc: 60.142% (4317/7178)\n",
      "\n",
      "Epoch: 87\n",
      "Training Loss: 0.036 | Acc: 99.453% (28552/28709)\n",
      "Validation Loss: 1.876 | Acc: 59.752% (4289/7178)\n",
      "\n",
      "Epoch: 88\n",
      "Training Loss: 0.040 | Acc: 99.272% (28500/28709)\n",
      "Validation Loss: 1.877 | Acc: 59.557% (4275/7178)\n",
      "\n",
      "Epoch: 89\n",
      "Training Loss: 0.074 | Acc: 98.258% (28209/28709)\n",
      "Validation Loss: 1.878 | Acc: 59.390% (4263/7178)\n",
      "\n",
      "Epoch: 90\n",
      "Training Loss: 0.101 | Acc: 97.238% (27916/28709)\n",
      "Validation Loss: 1.951 | Acc: 58.651% (4210/7178)\n",
      "\n",
      "Epoch: 91\n",
      "Training Loss: 0.150 | Acc: 95.378% (27382/28709)\n",
      "Validation Loss: 1.940 | Acc: 57.927% (4158/7178)\n",
      "\n",
      "Epoch: 92\n",
      "Training Loss: 0.153 | Acc: 95.078% (27296/28709)\n",
      "Validation Loss: 1.868 | Acc: 56.617% (4064/7178)\n",
      "\n",
      "Epoch: 93\n",
      "Training Loss: 0.143 | Acc: 95.594% (27444/28709)\n",
      "Validation Loss: 1.986 | Acc: 57.829% (4151/7178)\n",
      "\n",
      "Epoch: 94\n",
      "Training Loss: 0.116 | Acc: 96.712% (27765/28709)\n",
      "Validation Loss: 2.018 | Acc: 58.805% (4221/7178)\n",
      "\n",
      "Epoch: 95\n",
      "Training Loss: 0.103 | Acc: 97.029% (27856/28709)\n",
      "Validation Loss: 2.058 | Acc: 58.651% (4210/7178)\n",
      "\n",
      "Epoch: 96\n",
      "Training Loss: 0.090 | Acc: 97.395% (27961/28709)\n",
      "Validation Loss: 2.060 | Acc: 58.874% (4226/7178)\n",
      "\n",
      "Epoch: 97\n",
      "Training Loss: 0.078 | Acc: 97.921% (28112/28709)\n",
      "Validation Loss: 2.049 | Acc: 59.891% (4299/7178)\n",
      "\n",
      "Epoch: 98\n",
      "Training Loss: 0.064 | Acc: 98.457% (28266/28709)\n",
      "Validation Loss: 2.171 | Acc: 59.446% (4267/7178)\n",
      "\n",
      "Epoch: 99\n",
      "Training Loss: 0.057 | Acc: 98.701% (28336/28709)\n",
      "Validation Loss: 2.105 | Acc: 59.250% (4253/7178)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('==> Starting training')\n",
    "from torchsummary import summary\n",
    "\n",
    "for epoch in range(0, 100):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "torch.save(net, 'CNN_3subnets.pth')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e5e957-a324-4b07-b797-22b9aeab4a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcwUlEQVR4nO3d3ZJdVdk24IGSJn+dzj9JJBiwUAstt3TPI/YIPA4t2RAhgNGENOmQvw4JIu8Wo6iv3nXfq3p01M/3unafHr3mmnOu9dSqup8xX/v222+/HQAwxvjBv/sAAPjPoSkAMGkKAEyaAgCTpgDApCkAMGkKAEyaAgDT69v+4c7OzpFf5FXPx/3gB5t7WzvuixcvxvqFCxc21vb29uLaf/7zn7Gejvvq1atx7T/+8Y9YPzw8jPV2bMnLly9j/cWLF0eqjTHGV199FeuPHz+O9WfPnm2sXbp0Ka599913Y/3evXsba+0eT/fRGGOcPn061tP1ev78eVz76NGjWH/w4MHG2pMnT+Lar7/+Ota/+eabjbXV74W2PtX/r87sbvO+/VIAYNIUAJg0BQAmTQGASVMAYNIUAJg0BQCmrecU/pP98Ic/3Fhr+fDd3d1YP3Xq1MZay+u//no+vVeuXNlYSzMMY4zx2muvxfqZM2diPZ2zVBujZ50PDg421tpxN68yX37+/Pkjv3bK+o/Rr+cbb7wR6+matHPaZj/Sfdru4ZXr0da2WZqVWZt2zv6vzjGM4ZcCAN+jKQAwaQoATJoCAJOmAMCkKQAw/UsiqS3+1eonTpyI9RQlbFG/Vk9bA7fjSpHTMfK23i0S17YEb/WTJ09urLWtmPf392M9bbfctlpuW4I3aQvqFtN9+vRprJ87d25jLW3Z3Y5rjL6tdzr2ds7aFu/pXvjiiy/i2navpDhsi8q2bdZXI6387/xSAGDSFACYNAUAJk0BgElTAGDSFACYNAUApmObU1jZErlt1dzy/ml92/p3ZQvdlFsfo2+XfNTXHaPn3lt+/O7du0eqjZG3xh4j58/b+0qZ+THGOHv2bKyn6522QR+jzwpcvXo11pPDw8NYb/Mb6R5vMyntM5DOedtO/N69e7GethRvn/v2vto5S/dhm+1YmXH4/33bbb8UAJg0BQAmTQGASVMAYNIUAJg0BQAmTQGA6V/yPIWm7ffe8szffPPNxlrLtTcpw72aR05Z6DaH0GYFPv3001j/8ssvj3RcY6w9/6Jlz9szD27cuBHradagPTujzSFcvHhxY609T6Hl+R89ehTrK/f4yuxHy/OvPBPh5cuXcW27D9scULqX2rMa2vv6b35Wg18KAEyaAgCTpgDApCkAMGkKAEyaAgCTpgDAtPWcwsrzElr2fHXf9N3d3Y211VmClG1vufd2ztJx37lzJ6798MMPl147nfOWH2/58PT8i/ZsjDYrcP369Vi/cOHCxlp7nkKbh0n3YXvuQMu9tzmFJ0+ebKy1ZzW0OYWUuW+fvfashnS923zF06dPY/3x48dHXp9macbo93g6522G4T/9eQt+KQAwaQoATJoCAJOmAMCkKQAwaQoATMe2dXaKOLbIaduet0XXUvwybTk8Rt+iOsVOW6ytRSDTdsq3b9+Oa9v7ev78eaync9YijJcvX471d955Z2Ptvffei2tbtLOd03Pnzm2stWh0k+KZbfv3FD8eY4wHDx7EeopXtm27W8Q43Qstmtnq6bVbTLfFYdv3StrqvMVZ22un+7B99v7TI6t+KQAwaQoATJoCAJOmAMCkKQAwaQoATJoCANPWcwptW+GUV2555JQtb/+7acfdcu8pU9xmHNrWv3/961831tocQqu395XmAdocQtu++v33399Ye+utt+LaNiPRZg3SNWnnpN1nKX/etq9u5+zhw4exfnBwsLGW5l3GWNuWe3VWIH222/bubX7pxYsXsZ5mJNqM0cr3XZszaN+HbX2bc1jllwIAk6YAwKQpADBpCgBMmgIAk6YAwKQpADAd25xCkp5JsE29SXnmNkvQsukpN99y0vv7+7Gezunrr+dL0+orzzxoswS3bt2K9XfffXdjrT0voc0ptOvZ8udJy4enOYV2L7S8f9r7f4x8PduzHO7fvx/rn3/++cZam59ozyVI2rVs12PluQNtVqDNSKTPX5vdaPdCe+30vXEcMwx+KQAwaQoATJoCAJOmAMCkKQAwaQoATFtHUts2tysRrVepxd7aFtQp4tW2xm7RsvTabe2lS5di/ec//3ms/+QnP9lYa5HUtHaMMa5du7ax1ravbvUWjU4xxRYFbPV0j7fjbv+7xbLTfdw+X+2zm+7D1a3n07bcLc7aPpstvpxiwi3S3aKdKZ7cYu7tWq98b7RrvQ2/FACYNAUAJk0BgElTAGDSFACYNAUAJk0BgGnrOYUmZXNbdrZlgltut23HvPK/X758ubHWsudN2r635ahv3ry5VH/vvfc21tocQtuW++zZsxtrLVu+MocwRr6X2n3Y8uUref72v5v0vs6cORPXts9HmiU4PDyMa9usTsrkt/mKds7a9tfptdt3TrvP0r3QtlFv76t99tP3zsp24t/xSwGASVMAYNIUAJg0BQAmTQGASVMAYNIUAJi2nlNYyWG3WYCWH297tqfse9r3fIy+t3nKQr/KrHN6JsEYY1y/fj3WV+YY2hzC7u5urKfr0TLYqznrdB+2e3jlf7d7uM20rN5LSXvfac6hXetnz57FeppjaN8LbY6hva82x5CcOHEi1tNntz0HotXbd1Ja3+6jbfilAMCkKQAwaQoATJoCAJOmAMCkKQAwHVskdSUK1WKKbbvlFDttUcAWD0vH1s5Ji9yl6NmFCxfi2hYbvXLlSqzv7e1trLUI8Eq0s51v/nfp87UaQ0zX8/Tp03HtuXPnYj1FUh88eBDXtkhpe98r26i3+zStb99nTXtf6f+3bbu34ZcCAJOmAMCkKQAwaQoATJoCAJOmAMCkKQAwbR2oPY4tWTdZ2WJ6jJxnbpnhldx8+98tC53mFNqswMWLF5fqKX/etg1eyWGvbo29Im19PUa/XunY20xK0157RZsrSffaymdvjHyPr2593c75yjVp92mqr84ptFmD9P9fvny59Npj+KUAwPdoCgBMmgIAk6YAwKQpADBpCgBMmgIA09aB2pZXThnw1Wx6yyuvaM9baJn9ZOUZFG2f+vPnz8d62wd/Z2dnY62955XnKTQr+fAx+izCipX7uJ2zNqeQ1q/OX6T17X+vzLSsPo9kpb46d5XOafvf7ZytzBocx2fTLwUAJk0BgElTAGDSFACYNAUAJk0BgElTAGA6tucppDzzyjMLxuhzCilz37LlLeuc/nfT8uFpH/u9vb249syZM0f+32Pk/Hi7XivPkWjnpN1nK/X22ivPNFh5FsMYa3v/t+ux8kyRdr5XZiBaXj89i2GMMZ4+fRrr6Zy3WYCV+aTVZ2O02ZA0W3Ucczp+KQAwaQoATJoCAJOmAMCkKQAwaQoATFtHUle2ZG0RrdXI6sr/bnG9FBVcia2NkWOjbevrFjltUdp0TVo8st0Lq+clWTm2dq1XtHPSYtWHh4exno69ne9WT/fC6rb3KSLZ7tHVc5q0LfPb+36VW4K3WGmqr24JPoZfCgB8j6YAwKQpADBpCgBMmgIAk6YAwKQpADAd25xC2oq25aRf5Ta2LbfbtqB+8eLFxlrLE7fXTrMGJ0+ejGvbOWnHlnLYLUfdMtxpNmRl2+1tXjtl19tsx8r1fP78eVz75ZdfxnrLzb/KrZzTvEA7J+1eSdd7ZdvtMfr3xkqef2V2qh13+9+r52WVXwoATJoCAJOmAMCkKQAwaQoATJoCAJOmAMC09ZzCSm53NRP8xhtvxHrK9bbXbpnglHtvx7Xy2m2v+CdPnsT648ePYz3NnbQZiXbOUna9nZNWb3MKLbuerMzTPHv2LK5tz0vY3d2N9TTH0K7106dPY/3hw4cba3fv3o1r23xGOi+rz+1YmQdo91Grv8rvnCa979X/PYZfCgB8j6YAwKQpADBpCgBMmgIAk6YAwLR1JHUlPrYaPVuJWa1Gz1bilS1WeufOnY21dk7aOf3LX/4S6xcvXtxYu3LlSlzbYogXLlzYWHv77bfj2hYpbceW7pWV+OQYOQbctsbe39+P9T//+c+xfnBwcKTaGD2Sms5LW9vOWYrSrsQ+x+hboaeobXvtle2pX/XW1+n/i6QCcKw0BQAmTQGASVMAYNIUAJg0BQAmTQGAaes5hZXtYFfnFJqUOV6ZQ2j19r/b1tqXL1/eWPvpT38a1966dSvWT58+Hespc//HP/4xrm1bNafz8s4778S1Ozs7sf7b3/421s+ePbuxdv/+/bg25drHyLMGbc7gs88+i/VHjx7FetrWO73nMfq23GfOnDlSbYx+L6T7rM1AtK3M27G12ZGkfd+9yjmGlfWrMxBj+KUAwPdoCgBMmgIAk6YAwKQpADBpCgBMmgIA09ZzCq+/nv805XpXn2nQMsNpD/62duW1X7x4Ede2zH067papX80jp9dusxttBiLl5tvzEtp91vbvTzMvbQ7ho48+ivVPPvlkYy09N2CMnqlv7t69u7HWjrvNA6RnazTt83Xp0qWNtZMnT8a17XkJ7Zynz9Dh4WFc22YJVmYN2lzWynfWN998c6Rj+j6/FACYNAUAJk0BgElTAGDSFACYNAUAJk0BgGnrOYWWy13Jx7bMfcvttvqKdGwtz998+OGHG2t37tyJa9tzCVKufYw8L/D222/Htb/+9a9jPWXAr1+/Htfu7e3FeptjSM+waLMC7R5Oef+29//z589j/d133431dF7+9Kc/xbXtPr1x48bGWpvtaPfZlStXNtauXr0a17Y5nybdC212Y2UOqJ3vdq+02ankOL4L/VIAYNIUAJg0BQAmTQGASVMAYNIUAJi2jqS27V5TjGp1m+e2RW567bY9b7Ny7O21U/3HP/5xXPv+++/HejvuFItrWymfP38+1tOWxzdv3jzycY3RI6vp2FrU7+OPP471tGX45cuX49qf/exnsd7ulRQTfuutt+LaJ0+exHqKJ+/v78e1LWKcjm13dzeubVvTt7hs+85KVrbGXomUrr62SCoAx0pTAGDSFACYNAUAJk0BgElTAGDSFACYjm1OIWm525brbVvRruaCk5T3X9nGeYy8rXDL86ftjsfo+fF07G0upL3vlE2/du1aXNukWYEx8nbLqzMQ6ZxfunQprm2zHe0zkj4DbYvpNqeQ6ufOnYtr2z2+Mjdy7969WF/dcj9px5b+d7uWr/IxBCszDt/xSwGASVMAYNIUAJg0BQAmTQGASVMAYNIUAJi2nlNoud2WXU9annjlmQZtvmIlE9zec8sMp8x+e55Cy8W3PH/Kl7e17XkL6dkCbVagzUi067mS027/O73vdj3STMoY/R5PcwrpeQjb1L/66quNtdXPffpst/mJdk7ScY+Rz9nq7FT63mj3+Kp0Tle+h7/jlwIAk6YAwKQpADBpCgBMmgIAk6YAwPQv2Tq7Wd36OkXXVrepXYnDtrVvvvnmkWpj9IjjhQsXYj1tE922S97d3Y31dK+8ePEirl3d+je99krMcIy1+6zFFFsMOMUQWzSzva9Ub5/7Fid//PjxxtrBwUFc297Xs2fPYj3Fm49ji+lNViOpK1uCr2wXPl9/+T8A8F9DUwBg0hQAmDQFACZNAYBJUwBg0hQAmLaeU2i53rRla8tJt/x4y96mLHV77bS97hh5i+m2tuWNz58/v7GW5gjG6LMEbX3a6rll5pu0VXO7Hu1ar+TLV/L6Y+RjOzw8jGvbfMaZM2difWdnZ2NtdZYg3cdtK/P2GUj3wtOnT+PatrV2O+cr8xftOymtX5kzGGPtHl+d+RrDLwUAvkdTAGDSFACYNAUAJk0BgElTAGDSFACYtp5TaHuEpzzzajZ95ZkGLUfdXju97/a/T506FetpBqLNCrR6e+ZBel+r2fTnz59vrK3Mu2yzPmkZ7nQ9xsj7++/v7x/pmL7T5krSeWnnrN3j6Xq3tW1WID3zIN0nbe0269Ox/zuf29GsPBPhOJ4T4ZcCAJOmAMCkKQAwaQoATJoCAJOmAMCkKQAwbT2n0LLQScu1t73NmzTH0DK/K/W0V/wYPXueZg1OnjwZ17YZiDZXkmZH2pzCo0ePYj1d7/bcgHaftXsl3Qvtf6dnFoyRr3e7x2/fvh3rP/rRj2L9zTff3Fhrufh2bOl6r84SHBwcbKw9fPgwrm33WXseQ3rf7T5qef90zlefp9CuV5v7WuWXAgCTpgDApCkAMGkKAEyaAgCTpgDAdPSc6f8jRbhWt5Jd2Q62xb/asaX17X+37atTJHVl2+0x+jlLMcQvv/wyrn38+HGsnz9/fmNtdZvnVn/x4kWsJy3ql/736vt68uRJrF+4cOHIr70ScWyR03YvpNjp/fv349p2H7ZIajrnq5HUdM5X4qxj9OuV1q9su/0dvxQAmDQFACZNAYBJUwBg0hQAmDQFACZNAYDp2OYUUj625XZbvW1Fm6zOSKT1LR/etolOcwptG+eWs2555a+++mpjreWkr127FutphuLBgwdHPq4x+nbk6bykbZzHGOPjjz+O9ZSbb/fw2bNnY71tlZ7uwzZf0bZ4T9tjtzmFtr31/v7+xlqbQ2iv3e6VlfmmJn0nrW5t3T5/6bO9+n03hl8KAHyPpgDApCkAMGkKAEyaAgCTpgDApCkAMG09p7DyXIKW529zCC2Tn9a3rHLLFKfnDrRnGpw4cSLW0/tqa5uVrPSVK1divWXu0zlr2fM7d+4svXZ65kGbU7h3716sp2Nr9/Avf/nLWG/XK9Xb56Pl3g8PDzfW2jML2vVMMxBtziCt3WZ90r7PVp6P0e6FNjeyMqdwHPxSAGDSFACYNAUAJk0BgElTAGDSFACYto6ktshcimG1yNxK5LStb1vJvsqobYuVpkjrynbhY/Rzuru7u7HWorbtnKbXvnXr1pGPa4y+3XKKlaao7Bg9ipuuSdsm/caNG7Heji3Fads5a9HOtP11i6Q+fvz4yK+d4sNj9Mhpi26uaJ+/lW25V487ff6OY7twvxQAmDQFACZNAYBJUwBg0hQAmDQFACZNAYBp6zmFkydPxnqaY1jdprbl4lOmuGWCW643vXabBWizHel/t/fcrMyGrL52yp+3/93y/u1eeueddzbW2ixAy82nOYa2ts2stPv0wYMHG2ttDiFtjd3+d5phGKPPKaRZg5UtvcfoW1Cn74X2ndM+P+l7ox1Xqx/HrMEKvxQAmDQFACZNAYBJUwBg0hQAmDQFACZNAYDp2J6nkHK9bcah5ZVbpjhl19txr8wpNC2PnPLlLVPf3lfL86f17bWfPXsW63fu3NlYa89DaPnwFU+ePIn1v//977Ge8vxt7/9z587F+tWrV2M9zTm099Wu58OHD4/8v9ssQfpst9mOdL7H6Pf4zs7Oxlp7XsJKvX3u2/fdyoxR+17Yhl8KAEyaAgCTpgDApCkAMGkKAEyaAgDT1pHU5tSpUxtrLWLVInNvvPFGrKdoZ4uWtWNLkdQWzXz69Gmsp/UtrtdibysODg5i/eOPP471dOx7e3txbYsvtxhi2sq5xUbTPTzGGGfPnt1Ya9Hm/f39WG/xy1u3bm2stW2529baKSLZ7rMWgUyf7fae27bd7Zynz/5q9Dmds/Z9thqDT8d+HNtu+6UAwKQpADBpCgBMmgIAk6YAwKQpADBpCgBMW88ptO2rU71ly1u2tmWhU663/e+Vets2+KOPPor13/zmNxtrbcbh9OnTsd6kGYmWa79582aspxx1u4/aHENbn7Z6bnMKrf7JJ59srP3tb3+La9t2yW0+I2Xf2/9uuff0+WyZ+3bO0lbpaYv1dlxj9HshzSm02Y52ztI5b2tXv5PS56vNZW3DLwUAJk0BgElTAGDSFACYNAUAJk0BgElTAGDaek6h5ahTNrflqNvzEpqVvdFbpjjV2/zEBx98EOt/+MMfNtauX78e17br0c5pype369WeI5H24G856rbHfrvWacaizZWkGYcx8txJe17Czs5OrK9k19u90O7TdF7aOUnPrxgjz3a0tcfxbICjajMS7TOSvMo5hePglwIAk6YAwKQpADBpCgBMmgIAk6YAwKQpADBtPafQpGxty6av5nZXrMwptLUvXryI9d///vcbazdu3Ihr2xzC7u5urKfnMZw9ezaubRnt9CyItL/+GH1OoT1nItXb3v9pvqKtv3jxYlzbZgnaOU+fodW5kjQv8PDhw7g2zSGMkZ8z0T7Xq88lWFm78r2wOmewsr49Y2IbfikAMGkKAEyaAgCTpgDApCkAMGkKAExb55da1KnF/ZLVrbPTNrftuNu2wiuR1Obzzz/fWPvd734X1545cybWf/GLX8R6iqS2+OSJEydiPcUzr127Fte2rZpbRPKLL77YWGuR06+//jrWUxSwxa7b/25SrLRtCd5ivuk+vH37dlybthMfI3++WvRyNcr+Kre3Tse2+r7ad1ZaL5IKwLHSFACYNAUAJk0BgElTAGDSFACYNAUApq1DrS3zm+ptDmE1b7yzs3PktW2+ImWCV+cUUqb4s88+i2vTtttj9Fz8r371q421NPcxxhh7e3uxnmYo0rUao89AtBz2qVOnNtbaOWn1dL1b9vzg4CDW2/xF2nI8zRmMkbevHiPfa20OoZ2zlc/Pq6y3be3brE7SvnNWt9ZO57St3YZfCgBMmgIAk6YAwKQpADBpCgBMmgIAk6YAwLT1nELLI7e96pOW223Z9aQdd3ueQju2lbUpb9xmBdoe+R988EGspwz3e++9F9fevHkz1tP7btey3Udt/YULFzbW2kxKy66na/L8+fO4tr12u55p1qDNITx69OjIr90y9y0X3+7jpH1+2mc3zbS099VmINLs1cq8yzb1lWc5bMMvBQAmTQGASVMAYNIUAJg0BQAmTQGAaetIarMSr1zdTjnFAVtUsMXHUnStbePcomUr8bF2TttWzoeHhxtrn376aVz7+PHjWH/rrbc21s6dOxfXtnPa7oX0vlsMsUVSU6y0nZMWG719+3as379/f2Ot3Qutnt73cUQcN2nHtfr5Sf+/RWnT52OMMS5evLixlmLRY6zdZ2Pk+7h9l27DLwUAJk0BgElTAGDSFACYNAUAJk0BgElTAGDaek5hZZvakydPxrUtW9tyu0+fPt1Ya3MIKxnvlqlfyVGvbLs9Rj+np06dOvLadj1S5j697jb1tGXxGDnb3o67zbSkepojGGOMu3fvxnrb3jrdD6vZ9LRdebvPVj4/q3MIKzMU7X21mZb0nXP58uW4ts3qtJmXJ0+ebKy17+lt+KUAwKQpADBpCgBMmgIAk6YAwKQpADBpCgBMW88ptFxvmkVoef72v1efiZCsZJ3b2papT1no9r/bOW2vffr06Y21M2fOxLVtL/qUlW7XKmXmx+i5+PTa7X+3PfRTfjzl1sfoe+ivfL7aOUm59jHyNWn3Ycvzp1mE1VmcNueQtHO28p3Szvf169djPT2rYYx8L7XP/Tb8UgBg0hQAmDQFACZNAYBJUwBg0hQAmDQFAKat5xRapjjlw9vzFFYz3ilz/O/MOrdZghXtf6/MMbTr1eYU0jlt56xdj7ZffMvNJ22OId1L7T5bnStJn7+Dg4O4dn9/P9aT1evVzkuy8p0zxhgnTpw48v9u0rM52nve3d2N9b29vVhP90q7XtvwSwGASVMAYNIUAJg0BQAmTQGASVMAYNo6M9mifivxr7Ql8Rg9erYSe2v/eyXitbIdcovh7uzsxHqLjaaIZItHtnhlOmevOpKa3nd77XZO03lp16vFfFfO6YMHD468doz8+Vz97KX66r3QvlfSvdA+HysR43ZcbVvutj5tbd+27d6GXwoATJoCAJOmAMCkKQAwaQoATJoCAJOmAMD02rcre0cD8F/FLwUAJk0BgElTAGDSFACYNAUAJk0BgElTAGDSFACYNAUApv8BYe0bVHzIer0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "net = torch.load('CNN_3subnets.pth')\n",
    "net.eval()\n",
    "net.to(device) \n",
    "\n",
    "image_path = 'image1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_pil = Image.fromarray(image)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "input_tensor = transform(image_pil)\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "input_np = input_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "plt.imshow(input_np, cmap='gray') \n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(input_tensor)\n",
    "\n",
    "_, predicted = outputs.max(1)\n",
    "\n",
    "print(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c23dc9-b14b-4380-95ea-c0de287a44a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3ccdc-2f62-4ba9-9bc9-8263265d793a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
